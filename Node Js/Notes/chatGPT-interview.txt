â“ What is an "Events Module" and "EventEmitter"  in Node.js?

ğŸ‘‰ Events is core module.
ğŸ‘‰ The 'Events module' provides a way of 'working with events'.
ğŸ‘‰ Used to "create" and "handle" "custom events".
ğŸ‘‰ Implements an "event-driven architecture"
ğŸ‘‰ It allows developers to emit (trigger) and listen (handle) for custom events.
ğŸ‘‰ Event is basically a 'signal' that indicates something has happened in your application and you have to handle that event. 
Like when a connection is made or a file is opened. Every action on a computer is an event. 
ğŸ‘‰ lots of node class/modules raises different kinds of events and in your code you have respond to that events.


EventEmitter class: 

ğŸ‘‰ "EventEmitter" is "class" provided by the "events module".
ğŸ‘‰ we create "Instances" of "EventEmitter class" 
ğŸ‘‰ Many built-in Node.js modules (like http, fs, net) inherit from EventEmitter, making them event-driven.
allows us to:
ğŸŸ   Define (listen for) events using .on() or .addListener().
ğŸŸ   Emit (trigger) events using .emit().
ğŸŸ   Remove event listeners(callback fucntion) using .off() or .removeListener().

ğŸ‘‰ It follows the "Publisher-Subscriber model", where:

ğŸŸ  The publisher (emitter) generates events.
ğŸŸ  The subscriber (listener) waits for and responds to those events.


Example 1: Creating & Handling Events with EventEmitter
```
const EventEmitter = require('events'); 

// Create an instance of EventEmitter
const eventEmitter = new EventEmitter();

// Define an event listener
eventEmitter.on('greet', (name) => {   // callback function is called "event listener"
    console.log(`Hello, ${name}!`);
});

// Emit (trigger) the event
eventEmitter.emit('greet', 'John');

```

Example 2: Handling Multiple Listeners for the Same Event
```
const EventEmitter = require('events');
const eventEmitter = new EventEmitter();

eventEmitter.on('order', () => console.log('Order received.'));
eventEmitter.on('order', () => console.log('Processing payment...'));
eventEmitter.on('order', () => console.log('Order shipped.'));

eventEmitter.emit('order');

```

Example 3: Removing Event Listeners (callback function)
```
const EventEmitter = require('events');
const eventEmitter = new EventEmitter();

const eventListener = (name) => {
  console.log(`Welcom ${name}`)
};

eventEmitter.on("greet", eventListener)

eventEmitter.emit("greet", 'Adesh');

eventEmitter.off("greet",eventListener )
```

Example 4: Emitting Events Only Once with .once()
```
const EventEmitter = require('events');
const eventEmitter = new EventEmitter();

eventEmitter.once('connect', () => {
    console.log('Connected to the server.');
});

eventEmitter.emit('connect');  // âœ… Will execute
eventEmitter.emit('connect');  // âŒ Will NOT execute again
```


ğŸŸ  Inheriting from EventEmitter (Custom EventEmitter Class): 

ğŸ‘‰ Many built-in Node.js modules (like http, fs, net) inherit from EventEmitter, making them event-driven.
ğŸ‘‰ In bellow ex we created a "custom class" that extends EventEmitter. This allows us to create our own event-driven objects.

```
const EventEmitter = require('events');  // Import the EventEmitter module

// Create a class that inherits from EventEmitter
class MyEmitter extends EventEmitter {}  // âœ… Custom class extending EventEmitter

const myEmitter = new MyEmitter();  // âœ… Create an instance of MyEmitter

// Attach an event listener
myEmitter.on('alert', (msg) => {
    console.log(`ALERT: ${msg}`);
});

// Emit the 'alert' event
myEmitter.emit('alert', 'Low disk space!');

```


============================================================================================================================================================



â“ Event-Driven Architecture in Node.js:


An event-driven architecture (EDA) is a design pattern where application components communicate via events instead of direct method calls. 
In this model, events trigger specific handlers (listeners) that respond asynchronously.

Event is basically a 'signal' that indicates something has happened in your application and you have to handle that event. 
Like when a connection is made or a file is opened. Every action on a computer is an event. 

Node.js is built on this event-driven, non-blocking architecture, making it highly efficient for handling multiple concurrent operations without creating multiple threads.

ğŸ”¹ How Does Event-Driven Architecture Work in Node.js?

Node.js uses an "Event Loop" and the "events module" to handle events.

1. Event Emitter (Publisher-Subscriber Model)
A publisher (emitter) generates an event.
A subscriber (listener) waits for that event and executes a callback function when the event occurs.

2. Event Loop
Node.js listens for incoming requests and adds them to the Event Queue.
The Event Loop processes them asynchronously, delegating I/O tasks (like database queries, file reads) to the system.

3. Callbacks & Handlers
Once an operation completes, a callback function executes to handle the response.

Example: Event-Driven Programming in Node.js



============================================================================================================================================================




â“ What is Node.js, and how does it work?


ğŸ‘‰ Node is not a programming language nor its a framework it is just a open source, cross platform 'runtime environment' for 
executing js code outside a browser.
ğŸ‘‰ It is built on Google Chrome's V8 engine, which makes it fast and efficient
ğŸ‘‰ we use Node js to build backend services also call APIs.
ğŸ‘‰ Node applications are 'Asynchronous by default'.
ğŸ‘‰ In node we have a 'single thread' to handle 'all requests'.
ğŸ‘‰ Node.js allows developers to build scalable network applications using JavaScript on the server-side, making it ideal for backend development, APIs, and real-time applications.

-> up to 2009 only way to executing js code was inside a browser.  A browser provide a runtime environment for js code.
-> so every browser have "JS Engine" that takes our js code and converts it  into 'machine code' that computer understand.
-> Microsoft edge uses 'chakra', firefox uses 'SpiderMonkey' and chrome uses 'V8' and because of this verities of "JS ENGINE" 
sometimes the js code can behave differently browser to browser.
->In 2009,'Ryan Dahl' the creator of node came up with brilliant idea. He took google v8 engine which is the fastest js engine out 
there and embedded it inside a 'c++ program' and called that  program  'Node.exe' means Node. 
-> so similar to browser, Node became runtime environment for js code. 
-> Node contain js engine, with certain objects which provides an environment for executing our js code.
-> for ex we don't have 'document', 'window' object in a node instead we have 'global' object that gives us 
more interesting capabilities. for ex we can work with file system ,  listen for request like "http.createServer()" 
in a given port. and so on we can't do this kind of stuff inside a browser.
-> In summary Node is a program that contain chrome v8 engine plus some additional modules which gave us some capabilities not 
available inside a browser.
-> we can work with file system , os, network and so on..
-> Both  chrome and node share same V8 engine but they provide different runtime environment for js code to run.



How Does Node.js Work?

Node.js follows a non-blocking, event-driven architecture, which makes it highly efficient for handling multiple concurrent connections. 
Hereâ€™s how it works:

1. Single-Threaded Event Loop:
Unlike traditional web servers (e.g., Apache) that use multiple threads for handling requests, Node.js uses a single thread to process all requests asynchronously.

2. Asynchronous and Non-Blocking I/O:
Instead of waiting for a task (e.g., database query) to complete before handling another request, Node.js uses callbacks, promises, or async/await to continue execution.
This allows Node.js to handle thousands of requests concurrently.

3. Event-Driven Architecture:
Node.js operates on an event loop that listens for events (e.g., HTTP requests, database queries) and processes them using event handlers.
The Node.js "EventEmitter module" is used to trigger and listen to events.

4. V8 Engine for Fast Execution:
Node.js uses Googleâ€™s V8 JavaScript Engine (also used in Chrome) to execute JavaScript code quickly by compiling it into machine code.

5. Built-in Modules & npm (Node Package Manager):
Node.js provides built-in modules (like fs for file handling, http for creating servers, and path for file paths).
npm (Node Package Manager) allows developers to install thousands of libraries and frameworks (like Express.js for building APIs).


Use Cases of Node.js
âœ… REST APIs & Microservices
âœ… Real-time applications (chat apps, WebSockets)
âœ… Server-side rendering (SSR) for React, Next.js
âœ… IoT (Internet of Things) applications
âœ… File system automation









































How do you implement authentication in Node.js?



Check Autheticartion file






=====================================================================================================================================================================











key difference between worker processes and worker threads: 


1. Worker Processes

Definition: Worker processes are independent instances of a program running separately from the main process.
Memory: Each worker process has its own memory space, meaning they do not share memory with the main process.
Communication: Processes communicate via Inter-Process Communication (IPC), which can be slower due to data serialization/deserialization.
Use Case: Useful for CPU-intensive tasks, process isolation (e.g., microservices), or handling multiple users independently.

In the cluster module, we create "worker processes", not "worker threads". 
Each worker is a separate process with its own memory space, running independently from the main process (master process).

Example in Node.js: child_process module or clustering (cluster module).
```
const { fork } = require("child_process");

const worker = fork("worker.js"); // Creates a separate process
worker.send("Hello from main process");
worker.on("message", (msg) => {
    console.log("Message from worker:", msg);
});
```


2. Worker Threads
Definition: Worker threads allow parallel execution within the same process but in separate threads.
Memory: Unlike processes, worker threads share memory with the main thread (via SharedArrayBuffer or message passing).
Communication: Uses message passing, but since they are in the same process, communication is faster than IPC.
Use Case: Suitable for CPU-bound tasks, such as encryption, file processing, or complex calculations.

Example in Node.js: worker_threads module.
```
const { Worker } = require("worker_threads");

const worker = new Worker("./worker.js", { workerData: "Hello from main thread" });

worker.on("message", (msg) => {
    console.log("Message from worker:", msg);
});
```


| ----------------- | -------------------------------------------------------------- | ---------------------------------------------------------- |
| Feature           | Worker Processes                                               | Worker Threads (Worker Threads)                            |
| ----------------- | -------------------------------------------------------------- | ---------------------------------------------------------- |
| **Isolation**     | Completely separate process                                    | Runs in the same process but in a separate thread          |
| **Memory**        | Each process has its own memory                                | Threads share memory (can be an advantage or disadvantage) |
| **Communication** | Uses IPC (slower)                                              | Message passing (faster) or shared memory                  |
| **Performance**   | Higher overhead (process creation and communication)           | Lower overhead (faster execution within the same process)  |
| **Use Case**      | Suitable for CPU-heavy & isolated tasks (e.g., separate users) | Best for parallel computations inside a single process     |
| ----------------- | -------------------------------------------------------------- | ---------------------------------------------------------- |


============================================================================================================================================================

â“ What are worker threads in Node.js?


Node.js is single-threaded by default. While this is great for handling I/O operations (like file reading, network requests, or database queries), 
it struggles with CPU-intensive tasks (e.g., large calculations, image processing, or cryptography).

In the "cluster module", we create worker processes, not worker threads. Each worker is a separate process with its own memory space, running independently from the main process (master process).



Worker Threads solve this by enabling true multithreading in Node.js, allowing tasks to run in separate threads without blocking the main event loop.

ğŸš€ Definition: 

'Worker Threads' in Node.js allow running JavaScript code in parallel threads inside the same process. 
This helps perform CPU-intensive tasks without blocking the main event loop.

ğŸ‘‰ Why use Worker Threads?

Node.js is single-threaded by default.
Heavy computations block the main thread, making the app unresponsive.
Worker Threads allow parallel execution without blocking the main thread.
They are best for CPU-heavy tasks like image processing, ML, and complex calculations.


How Worker Threads Work

Creates 'actual threads' inside a 'single process
Threads share memory, allowing for efficient data processing.
Each worker thread runs in its own V8 execution context.
A worker thread runs in a separate execution context.





âœ… Best for: CPU-intensive tasks (e.g., image processing, large computations).
âŒ Not ideal for: Scaling HTTP servers (since requests are handled in the same process).




=========================================================================================================================================================================

â“ What is Node.js Clustering? ğŸš€

ğŸ‘‰ Node.js runs on a 'single thread', meaning it can only use one CPU core at a time. But modern computers have multiple CPU cores.

We need more CPU cores to handle 'multiple tasks at the same time' efficiently.
A CPU core is like a brain inside the processor that handles tasks.

Think of it Like a Kitchen:
A single-core CPU is like one chef cooking everything alone.
A multi-core CPU (e.g., 4 cores) is like 4 chefs working together, making food faster.

What Does a CPU Core Do?
âœ” Executes instructions (running apps, calculations, tasks).
âœ” The more cores, the more tasks can run simultaneously (better multitasking).
âœ” Modern CPUs have multiple cores (dual-core, quad-core, octa-core, etc.) for better speed and efficiency.

A CPU with 8 cores can handle 8 different tasks at the same time, making everything faster and smoother! ğŸš€



ğŸŸ¢ Clustering allows Node.js to use 'all CPU cores' by creating 'multiple processes'/'workers processes' that share the same server port. 
This improves performance and handles more traffic efficiently.

In the cluster module, we create worker processes, not worker threads. Each worker is a separate process with its own memory space, running independently from the 
main process (master process).


ğŸ‘‰ Clustering is the technique of running multiple instances of a Node.js application on different CPU cores to improve performance and handle more requests.
ğŸ‘‰ By default, a Node.js application runs on a 'single thread', meaning it can only use one CPU core. 
Clustering allows Node.js to create multiple worker processes, each running on its own core, enabling better scalability.


Why is Clustering Used?
âœ… Improves performance by using all CPU cores.
âœ… Handles more traffic without slowing down.
âœ… Fault tolerance â€“ if one worker crashes, others keep running.
âœ” Handles More Traffic â€“ Multiple workers process requests at the same time. 
âœ” Prevents Crashes â€“ If one worker fails, the app doesnâ€™t stop.
âœ” Uses Multi-Core CPUs â€“ Most servers have multiple cores, so clustering makes full use of the systemâ€™s power.


How Does Clustering Work? âš™ï¸

ğŸ‘‰ A 'master process' is created and it checks the number of CPU cores
ğŸ‘‰ The 'master process' forks (create) multiple "worker processes" to handle tasks.
ğŸ‘‰ Each 'worker process' runs its own Express.js server or instance of HTTP server, handling incoming requests like API requests, static files, and database queries.
ğŸ‘‰ The OS distributes incoming requests to different workers
ğŸ‘‰ If a worker process crashes, the master automatically restarts it.
ğŸ‘‰ A load balancer (Nginx) distributes requests among workers process.
ğŸ‘‰ This allows Node.js to handle more requests in parallel and use all CPU power.
ğŸ‘‰ It is useful for scaling applications by utilizing multiple CPU cores.


Ideal Use Cases for Cluster Module
âœ” I/O-heavy tasks (handling multiple network requests, databases, APIs).
âŒ Not ideal for CPU-heavy tasks (hashing, encryption, complex computations, image, video related tasks). Instead, use worker threads for CPU-intensive tasks.


Key Takeaways:

Each worker is a separate process, not a thread.
Workers do not share memory (unlike worker threads).
Workers communicate with the master process via IPC.
Useful for scaling Node.js applications by utilizing multiple CPU cores.
If a worker crashes, the master process can restart it.




## **ğŸŸ¢ Applications That Benefit from Clustering**
| ----------------------------------- | ------------------------------- | -------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------- |
| Application Type                    | Needs Clustering?               | Why?                                                                                                                                                                                   |
| ----------------------------------- | ------------------------------- | -------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------- |
| Movie Rental Application            | âŒ Not Necessary                 | APIs mostly wait for database responses (I/O-bound). Clustering **won't help much** unless API traffic is huge. Instead, optimize DB queries & caching (e.g., Redis).                  |
| E-Commerce Application ğŸ›’           | âœ… Yes (If High Traffic)         | Handles many users, carts, and payments. Clustering helps **scale API requests** across multiple CPU cores. Also consider a **load balancer (NGINX, AWS ALB)** for better performance. |
| Image Processing App ğŸ–¼ï¸            | âœ… Yes (Highly Recommended)      | CPU-heavy tasks like **resizing images, applying filters** are slow on a single thread. Clustering allows processing multiple images in parallel, speeding up performance.             |
| Video/Image Converter ğŸï¸           | âœ… Yes (Critical)                | Converting formats (e.g., MP4 â†’ MP3) is CPU-intensive. Clustering distributes workload across multiple processes for **faster conversions**.                                           |
| Chat/Messaging App ğŸ’¬               | âŒ No (Use WebSockets Instead)   | Mostly I/O-bound (real-time messages). Clustering **wonâ€™t improve performance much**. Instead, use **WebSockets (Socket.io) + Redis pub/sub** for scaling.                             |
| Streaming Service (Like Netflix) ğŸ“º | âœ… Yes (For API & Encoding)      | APIs for fetching movies need clustering **if millions of users**. Video encoding (converting 4K â†’ 1080p) is CPU-heavy, so clustering helps.                                           |
| Machine Learning/AI API ğŸ¤–          | âœ… Yes (If CPU-Based)            | AI models doing **heavy calculations** (e.g., image recognition) can use clustering. But if using a **GPU**, clustering may not be needed.                                             |
| Web Scraping App ğŸ•·ï¸                | âœ… Yes (For Speed)               | Scraping multiple pages from different websites can be parallelized using clustering to **speed up extraction**.                                                                       |
| File Upload & Compression App ğŸ“‚    | âœ… Yes (For Faster Processing)   | If users upload **large files**, clustering allows multiple uploads to be **processed in parallel** instead of queuing.                                                                |
| Authentication API ğŸ”               | âŒ No (I/O-Bound, Not CPU-Heavy) | Mostly handles **database queries (login, signup, JWT tokens, OAuth)**. Clustering **wonâ€™t help** much here. Instead, optimize DB queries & caching.                                   |
| ----------------------------------- | ------------------------------- | -------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------- |



ğŸ›‘ When NOT to Use Clustering?
âŒ If your application is I/O-bound (mostly waiting for databases, APIs, or file reads).
âŒ If youâ€™re using in-memory storage (like storing sessions in-memory, which isnâ€™t shared across workers).
âŒ If your app is running inside a containerized environment like Docker, where scaling is handled at a higher level.

=========================================================================================================================================================================

â“Clustering vs. Cluster Module in Node.js

ğŸ‘‰ Clustering and the Cluster Module are related but not exactly the same
ğŸ‘‰ Clustering (Concept), Cluster Module (Implementation)


In the cluster module, we create worker processes, not worker threads. Each worker is a separate process with its own memory space, running independently from the main process (master process).


1ï¸âƒ£ Clustering (Concept)

Clustering is the technique of running multiple instances of a Node.js application on different CPU cores to improve performance and handle more requests.
By default, a Node.js application runs on a single thread, meaning it can only use one CPU core. Clustering allows Node.js to create multiple worker processes, each running on its own core, enabling better scalability.


2ï¸âƒ£ Cluster Module (Implementation)
The Cluster Module (cluster) is the built-in Node.js module used to implement clustering.

Creates multiple Node.js processes (workers) to utilize multiple CPU cores.
Each process runs a separate instance of the Node.js runtime.
Share the same server port across multiple workers.
Processes/workers do not share memory but can communicate via IPC (Inter-Process Communication).
âœ… Best for: Scaling an HTTP server to handle multiple requests.
âŒ Not ideal for: Sharing memory between workers.

ğŸ”¹ What Happens?
1ï¸âƒ£ The master process forks multiple worker processes (equal to the number of CPU cores).
2ï¸âƒ£ Each worker handles requests independently, improving performance.
3ï¸âƒ£ If a worker crashes, the master process restarts it.


It allows you to:

Fork multiple worker processes (each running a copy of the application).
Distribute incoming requests among workers (handled by the OS).


example of cluster module: 

```
const cluster = require("cluster");
const os = require("os");

if (cluster.isMaster) {
  cluster.schedulingPolicy = cluster.SCHED_RR; // Enable round-robin on Windows

  const numCPUs = os.cpus().length;
  console.log(`Master process ${process.pid} is running`);

  for (let i = 0; i < numCPUs; i++) {
    cluster.fork();
  }

  cluster.on("exit", (worker, code, signal) => {
    console.log(`Worker ${worker.process.pid} died, restarting...`);
    cluster.fork();
  });
} else {
  const http = require("http");
  const server = http.createServer((req, res) => {
    res.writeHead(200);
    res.end(`Handled by worker ${process.pid}\n`);
  });

  server.listen(3000, () => {
    console.log(`Worker ${process.pid} started`);
  });
}

```

On Linux/macOS, Node.js uses round-robin scheduling automatically.
On Windows, the default scheduling policy sends all requests to a single worker.
Setting "cluster.schedulingPolicy = cluster.SCHED_RR;" enables round-robin manually.

How the Code Works
1ï¸âƒ£ Master Process (Main Thread)
The script first checks if the process is the master (cluster.isMaster).
It determines the number of CPU cores using os.cpus().length.
It creates (forks) multiple worker processes equal to the number of CPU cores.
If a worker crashes, it automatically restarts a new worker (cluster.fork()).

2ï¸âƒ£ Worker Processes
If the process is not the master, it becomes a worker (else block).
Each worker starts an HTTP server listening on port 3000.
The server responds with a message indicating which worker (process ID) handled the request.



=========================================================================================================================================================================



â“ What is the difference between V8 and libuv?


ğŸ‘‰ V8 and libuv are both core parts of Node.js, but they serve different purposes.


1ï¸âƒ£ V8 executes JavaScript code.
2ï¸âƒ£ libuv handles async operations (e.g., file reads, network requests).
3ï¸âƒ£ Once an async task is done, libuv sends the result back to the event loop, which V8 then processes.


Example: How V8 and libuv Work Together

```
console.log("Start"); // V8 executes immediately

setTimeout(() => {
  console.log("Timeout callback"); // Handled by libuv, executes later
}, 1000);

console.log("End"); // V8 executes immediately
```




============================================================================================================================================================


â“ How Garbage Collection Works in V8 ğŸš€

ğŸ‘‰ Javascript:
-> Garbage collection (GC) is the process of automatically freeing up memory by removing objects that are no longer needed or accessible.
-> The garbage collector identifies and removes objects that are unreachable
-> JavaScript uses an automatic garbage collector, meaning developers don't need to manually manage memory.


example: 
function demo() {
    let obj = {
        name: 'Sample'
    };
    
    obj = null;  // The object "{name: 'Sample'}" is now unreachable
}
Explanation:
Initially, obj holds a reference to an object.
When obj = null; is assigned, the original object becomes unreachable because no variable is referencing it.
The garbage collector will clean up this object during the next GC cyc


ğŸ‘‰ Node js: 

V8 manages 'memory allocation' and 'garbage collection' (GC) automatically. 
It uses a 'generational garbage collection strategy' to efficiently clean up unused memory.

V8 uses two 'main types of garbage collection' based on object lifetime:

âœ… Young Generation (Scavenge GC) : 
-> Contains short-lived objects
-> Fast and efficient for short-lived objects.

âœ… Old Generation (Mark-Sweep & Mark-Compact GC)
-> Contains long-lived objects that survive multiple Young GC cycles.
-> More expensive than Young GC but necessary for long-lived objects.


V8 divides memory into different heap regions:
| ---------------------------- | -------------------------------- |
| Heap Region                  | Purpose                          |
| ---------------------------- | -------------------------------- |
| New Space (Young Generation) | Stores short-lived objects.      |
| Old Space (Old Generation)   | Stores long-lived objects.       |
| Large Object Space           | Stores large objects separately. |
| Code Space                   | Stores compiled JavaScript code. |
| Map Space                    | Stores metadata about objects.   |
| ---------------------------- | -------------------------------- |





============================================================================================================================================================


 â“What is Deno, and how is it different from Node.js?


Deno is a "modern runtime" for JavaScript and TypeScript, created by "Ryan Dahl" (the original creator of Node.js). It is designed to address some of Node.js's 
shortcomings.

Key Differences Between Deno and Node.js:

Security â€“ Deno runs in a sandbox and requires explicit permissions for file, network, and environment access.
Built-in TypeScript Support â€“ Deno natively supports TypeScript without needing extra configuration.
Simpler Module System â€“ Deno uses "URL-based module imports" instead of node_modules.
Built-in Utilities â€“ Deno provides built-in tools like a linter, formatter, and test runner.
Standard Library â€“ Deno includes a curated standard library, reducing the need for third-party dependencies.
Deno aims for a more secure and modern developer experience compared to Node.js. ğŸš€


============================================================================================================================================================



â“ How Node.js Handles Memory Leaks:

A memory leak occurs when a program fails to release unused memory, causing increased memory usage over time. This can lead to performance issues or crashes.


Node.js uses "automatic garbage collection" to free up unused memory. 

However, leaks can still happen due to:
-> Global variables that persist in memory.
-> Event listeners not being removed. Unremoved event listeners that keep references alive.
-> Unclosed timers or intervals (setInterval, setTimeout).
-> Closures and references that prevent garbage collection. Closures holding unnecessary references

How to Prevent Memory Leaks
âœ… Use WeakMaps for caching to prevent memory retention.
âœ… Remove event listeners when no longer needed. Unremoved event listeners that keep references alive.
âœ… Clear timers and intervals using clearTimeout() and clearInterval().
âœ… Avoid global variables and use let/const instead of var.
âœ… Monitor memory usage with process.memoryUsage() or tools like Chrome DevTools and heapdump.

Proper memory management helps keep Node.js applications efficient and stable. ğŸš€



=========================================================================================================================================================================


2ï¸âƒ£ How do you implement caching in Node.js?

Caching improves performance by storing frequently accessed data in memory, reducing database calls or expensive computations.

Types of Caching in Node.js:

1ï¸âƒ£ In-Memory Caching

Stores data in the applicationâ€™s memory (RAM).
Fastest but not persistent (data is lost on restart).
Best for small datasets or temporary caching.
Example: Using JavaScript objects, Map, or lru-cache.
âœ… Use Case: Fast lookups, session data, API responses.


2ï¸âƒ£ Distributed Caching

Stores cached data in external services like Redis or Memcached.
Can be shared across multiple servers, making it scalable.
Suitable for large-scale applications and persistent caching.
Example: Redis, Memcached.
âœ… Use Case: Caching database queries, authentication tokens, real-time data.


3ï¸âƒ£ Database Caching
Stores cache inside the database to reduce query execution time.
Methods:
Indexing: Speeds up searches.
Query caching: Stores query results.
Materialized views: Precomputed results stored as a table.
âœ… Use Case: Repeated database queries, analytics dashboards.


example: 

1ï¸âƒ£ In-Memory Caching example: 
```
function multiply() {
  let calculationData = {};

  return (num) => {
    if (num in calculationData) {
      console.log(`Data Coming from cache`);
      return calculationData[num];
    }
    else {
      calculationData[num] = num * num;
      return calculationData[num]
    }
  }
}
```


2ï¸âƒ£ Using Redis for Distributed Caching

'ioredis' is a powerful Redis client for Node.js that provides better performance, scalability, and advanced features compared to the default redis package.
```
const Redis = require('ioredis');
const redis = new Redis();

const cacheMiddleware = (req, res, next) => {
  const { customerId } = req.params;
  if(customerId){
    const cachedCustomer = await redis.get(`customer:${customerId}`);   //customer:1
    if(cachedCustomer)
      return res.status(200).json({ data: cachedCustomer })
  }else{
    const cachedCustomers = await redis.get(`customers`);
    if(cachedCustomers)
      return res.status(200).json({ data: cachedCustomers });
  }

  next();
}


app.get('/', cacheMiddleware, (req, res) => {
  try{
    cost customers = await Customer.find({});
    await redis.set('customers', JSON.stringfy(customers), "EX", 60);  // Cache for 60 seconds
    return res.status(200).json({ data: customers});
  }catch(err){

  }
})

createsimiilar to getCustomer
// await redis.set(`customer:${customerId}`, JSON.stringify(customer), "EX", 60); // Cache for 60 seconds

```




=========================================================================================================================================================================


What is a Load Balancer? ğŸ¤”

A load balancer is like a "traffic cop" for your servers. 
It "distributes" incoming requests across multiple servers so that no single server gets overloaded. 
This improves speed, reliability, and scalability of your application.

Why Do We Need a Load Balancer? ğŸš¦
Imagine you have a website or an app with millions of users. If all users send requests to one server, it will crash under heavy traffic. 
Instead, a load balancer will:
âœ… Distribute traffic evenly across multiple servers.
âœ… Prevent overload & crashes by redirecting requests if a server fails.
âœ… Improve speed by sending users to the nearest or least busy server.
âœ… Ensure high availability so users always get a response.

How Does a Load Balancer Work? âš™ï¸
User requests a website (e.g., opening example.com).
The request first goes to the load balancer instead of a direct server.
The load balancer decides which server should handle the request.
The server processes the request and sends a response back to the user.



Types of Load Balancers ğŸ—ï¸


1ï¸âƒ£ NGINX (Software Load Balancer) ğŸ–¥ï¸

NGINX is an open-source web server that can also work as a load balancer.
Nginx is a 'web server' that can also be used as a 'reverse proxy', 'load balancer', mail proxy and 'HTTP cache'. 
It is installed on a server and distributes traffic to backend servers.
Good for small to medium-sized applications.

ğŸ”¹ Example: A company has 3 servers running a web app. NGINX balances traffic among them:
```
User  â†’  NGINX Load Balancer  â†’  Server 1 / Server 2 / Server 3
```

2ï¸âƒ£ AWS ALB (Amazon Application Load Balancer) â˜ï¸

AWS ALB is a cloud-based load balancer offered by Amazon Web Services.
It works at the application layer (Layer 7) and routes traffic based on URL paths.
Ideal for large-scale cloud applications.

ğŸ”¹ Example: An e-commerce app has different servers for products and payments. AWS ALB routes traffic accordingly:
```
User  â†’  AWS ALB  
      â†’  `/products` â†’ Product Server  
      â†’  `/checkout` â†’ Payment Server 
```


Final Thoughts ğŸš€
If you're managing your own servers â†’ Use NGINX.
If you're using AWS and need a scalable solution â†’ Use AWS ALB.
Both ensure high availability, performance, and reliability for your app.


Reverse Proxy vs. Load Balancer: Are They the Same?
A Reverse Proxy is server that forwards client requests to one or more backend servers.
A Load Balancer can be a dedicated hardware device or software that distributes traffic among multiple servers.

Key Difference:
A reverse proxy can act as a load balancer, but a load balancer is not always a reverse proxy.
A load balancer's main job is distributing traffic, while a reverse proxy provides additional features like security, caching, and SSL termination.

| Feature  | Reverse Proxy ğŸ›¡ï¸      | Load Balancer âš–ï¸                      |
| Examples | Nginx, Apache, HAProxy | NGINX Load Balancer, AWS ELB, HAProxy |


=========================================================================================================================================================================

â“ What is a reverse proxy, and why would you use one with Node.js?

ğŸ‘‰ A reverse proxy is a 'server' that sits between clients and backend servers, forwarding client requests to the appropriate backend service.

Why Use a Reverse Proxy with Node.js?
âœ… Load Balancing â€“ Distributes traffic across multiple Node.js instances.
âœ… Security â€“ Hides internal server details, preventing direct exposure.
âœ… SSL Termination â€“ Handles HTTPS encryption, offloading SSL processing.
âœ… Caching & Compression â€“ Improves response time and reduces load.
âœ… Rate Limiting & DDoS Protection â€“ Filters and blocks malicious requests.


Reverse Proxy vs. Load Balancer: Are They the Same?
A Reverse Proxy is server that forwards client requests to one or more backend servers.
A Load Balancer can be a dedicated hardware device or software that distributes traffic among multiple servers.

Key Difference:
A reverse proxy can act as a load balancer, but a load balancer is not always a reverse proxy.
A load balancer's main job is distributing traffic, while a reverse proxy provides additional features like security, caching, and SSL termination.

| Feature  | Reverse Proxy ğŸ›¡ï¸       | Load Balancer âš–ï¸                      |
| Examples | Nginx, Apache, HAProxy | NGINX Load Balancer, AWS ELB, HAProxy |

=========================================================================================================================================================================


ğŸš€ How can you optimize API response time in a Node.js application?


1ï¸âƒ£ Implement Caching (Memory & Redis)
Store frequently requested data in memory (Map, lru-cache) or Redis.
Reduces redundant database queries.


2ï¸âƒ£ Optimize Database Queries
Use Indexing for frequently queried fields.

Use pagination (LIMIT, OFFSET) to fetch only required data.

4ï¸âƒ£ Use Compression (Gzip, Brotli)
Reduce response payload size to improve speed.
```
const compression = require("compression");
app.use(compression());
```
âœ… Result: Smaller response size, faster loading


5ï¸âƒ£ Optimize Middleware & Reduce Unnecessary Code
Remove unused middleware.
Avoid blocking operations in middleware.

âœ… Result: Faster request processing.


6ï¸âƒ£ Use Load Balancing & Clustering

Use Node.js Clustering to utilize multiple CPU cores.
Deploy load balancers (NGINX, AWS ALB) for distributing traffic.


7ï¸âƒ£ Reduce Payload Size (Use Proper Response Formats)
Use GraphQL or select only required fields in REST APIs.

Example (Selecting Required Fields in MongoDB):
```
const user = await User.findById(userId).select("name email");
```
âœ… Result: Lighter responses, faster API calls.


8ï¸âƒ£ Use HTTP/2 for Faster Request Handling
HTTP/2 allows multiplexing, reducing the number of requests.
âœ… Setup Nginx as a reverse proxy to enable HTTP/2.

9ï¸âƒ£ Implement Connection Pooling in Databases
"Reuse" database connections instead of "creating" a new one for each request.
```
const connectDB = async () => {
  try {
    await mongoose.connect("mongodb://localhost:27017/myDatabase", {
      useNewUrlParser: true,
      useUnifiedTopology: true,
      maxPoolSize: 10, // Set max connections in the pool
      minPoolSize: 5,  // Maintain at least 5 connections
      serverSelectionTimeoutMS: 5000, // Timeout if the server is unreachable
      socketTimeoutMS: 45000, // Close unused connections after 45s
    });
    console.log("MongoDB Connected with Connection Pooling âœ…");
  } catch (err) {
    console.error("MongoDB Connection Failed âŒ", err);
  }
};
```

Key Connection Pooling Settings:
|---------------------------|-----------------------------------------------------------|
| Option                    | Description                                               |
|---------------------------|-----------------------------------------------------------|
| `maxPoolSize`             | Maximum number of connections in the pool (default: 100). |
| `minPoolSize`             | Minimum connections to keep open.                         |
| `serverSelectionTimeoutMS`| Time to wait for a database connection before failing.    |
| `socketTimeoutMS`         | How long to keep an idle connection open before closing.  |
|---------------------------|-----------------------------------------------------------|

Why is Connection Pooling Important?
âœ… Prevents excessive database connections (avoids MongoServerError: Too many connections).
âœ… Reduces request latency (reuses open connections).
âœ… Handles concurrent users better in high-traffic apps.



ğŸ”Ÿ Monitor & Optimize Performance
Use New Relic, PM2, or Datadog for API performance monitoring.
Identify slow endpoints using console.time() or profiling tools.
âœ… Result: Continuous optimization.





=========================================================================================================================================================================



1ï¸âƒ£ What are the core modules in Node.js?

check module file.



=========================================================================================================================================================================


2ï¸âƒ£ How do you install Node.js and check its version?

1. Install Node.js:
Download the latest LTS version from Node.js official website.
Run the installer and follow the setup instructions

2. Verify Installation
After installation, open Command Prompt (Windows) or Terminal (macOS/Linux) and run:
```
node -v   # Check Node.js version
npm -v    # Check npm (Node Package Manager) version
```

âœ” If installed correctly, it will display the installed versions, e.g., v18.17.1. ğŸš€


Note: 
As of March 24, 2025, the latest Long-Term Support (LTS) version of Node.js is v22.14.0

Node.js v18, which was released on: October 25, 2022 (became LTS)
Node.js v20, which was released on: October 24, 2023 (became LTS)


=========================================================================================================================================================================



3ï¸âƒ£ What is npm? How does it work?


NPM : 

-> NPM Stands for "Node package manager".
-> npm is the default "package manager" for Node.js. 
-> It installed automatically with Node.js.
-> It helps developers install, manage, and share JavaScript packages (libraries or dependencies) easily.
-> We use NPM to download  3rd-party packages from NPM registry. as well as to create a node application.
-> NPM registry have millions of npm packages that you can download according to your application need.
-> popular npm packages are express, mongoose, nodemon, dotenv, bcrypt, helmet, joi

// Install a package
npm i <packageName>

// Install a specific version of a package 
npm i <packageName>@<version>

// Install a package as a development dependency
npm install <packageName> --save-dev

// Uninstall a package
npm un <packageName>

// List installed packages 
npm list â€”depth=0

// View outdated packages
npm outdated

// Update packages 
npm update

// bypass peer dependency conflicts
npm i --legacy-peer-deps 

If one package depends on another and you update a package, it can create dependency conflicts when the required versions donâ€™t match.
This can cause installation failures because npm strictly enforces peer dependencies in v7+. To bypass these conflicts, we use above command.



=========================================================================================================================================================================



3ï¸âƒ£ several ways to create a Node.js application:

There are several ways to create a Node.js application, depending on your project requirements. Here are the most common methods:

1ï¸âƒ£ Using npm init (Manual Setup)
The traditional way to start a Node.js application by manually setting up a package.json file.
```
npm init
```

2ï¸âƒ£ Using npx (Boilerplate Generator)
npx runs CLI tools without installing them globally.
```
npx express-generator my-app
```

3ï¸âƒ£ Using a Custom JavaScript File (Simple Script)
ğŸ‘‰ You can create a simple Node.js app without npm.
Create a new file, app.js
Write this code:
```
console.log("Hello, Node.js!");
```
RUN > node app.js


4ï¸âƒ£ Using a Framework (e.g., Express.js)
ğŸ‘‰ If building a web server, Express.js is the most common choice.



=========================================================================================================================================================================



2ï¸âƒ£ What is the purpose of package.json?

package.json is the "main configuration file" for a Node.js project.
 It contains metadata, dependencies, and scripts for he project.

ğŸ”¹ Purpose of package.json
Defines the project name, version, and description.
Lists dependencies required to run the project.
Specifies scripts to automate tasks (npm start, npm test, etc.).
Helps in versioning and package management.

ğŸ›  Example of package.json
{
  "name": "my-app",
  "version": "1.0.0",
  "description": "A sample Node.js project",
  "main": "index.js",
  "scripts": {
    "start": "node index.js",
    "dev": "nodemon index.js"
  },
  "dependencies": {
    "express": "^4.18.2"
  },
  "devDependencies": {
    "nodemon": "^2.0.22"
  }
}



ğŸ“Œ 2. What is package-lock.json?
package-lock.json is automatically generated when you install dependencies using npm install. 
It locks the exact versions of installed packages.

ğŸ”¹ Purpose of package-lock.json
Ensures the exact same package versions are installed on different systems.
Improves dependency resolution speed in future installations.
Helps team members and CI/CD pipelines install the same dependency tree.
ğŸ›  Example of package-lock.json (Simplified)

âœ… Always commit both to Git to maintain a stable project setup! ğŸš€




=========================================================================================================================================================================


8ï¸âƒ£ What are global objects in Node.js?


ğŸ‘‰ In Node.js, global objects are built-in objects that are available in all modules and can be accessed anywhere in the application without importing them.
ğŸ‘‰ The main global object is 'global', similar to 'window' in browsers.
ğŸ‘‰ Useful built-in objects include process, console, setTimeout(), and more.

- **Global objects** are properties of `global` (e.g., `global.process`).  


## ğŸ”¹ List of Important Global Objects in Node.js
|-----------------------|---------------------------------------------------------------------------|
| Global Object         | Description                                                               |
|-----------------------|---------------------------------------------------------------------------|
| `global`              | The root object that contains all global variables.                       |
| `process`             | Provides information about the **current Node.js process**.               |
| `console`             | Provides methods like `console.log()` for logging messages.               |
| `setTimeout()`        | Executes a function **after a delay**.                                    |
| `setInterval()`       | Executes a function **repeatedly at a fixed interval**.                   |
| `setImmediate()`      | Executes a function **immediately after the current execution cycle**.    |
| `clearTimeout()`      | Cancels a timeout set by `setTimeout()`.                                  |
| `clearInterval()`     | Cancels an interval set by `setInterval()`.                               |
| `clearInterval()`     | Cancels an interval set by `setInterval()`.                               |
|-----------------------|---------------------------------------------------------------------------|


ğŸ› ï¸ Examples of Global Objects

1ï¸âƒ£ global (Root Object)
console.log(global); // Prints all global properties

4ï¸âƒ£ process (System Info & Environment Variables)
console.log(process.env.NODE_ENV); // Prints the environment (e.g., 'development')
console.log(process.version); // Prints Node.js version
console.log(process.platform); // Prints OS platform (e.g., 'win32', 'linux')


============================================================================================================================================================







process:
The process object is a global object in Node.js that provides information and control over the current Node.js process
It allows interaction with the environment, system, and command-line arguments.


ğŸ› ï¸ Main Operations of process

1ï¸âƒ£ Get Node.js and System Info
console.log("Node Version:", process.version);    // Node Version: v18.16.0
console.log("Platform:", process.platform);         // Platform: win32


2ï¸âƒ£ Read Environment Variables (process.env)
console.log("NODE_ENV:", process.env.NODE_ENV);
console.log("Custom Variable:", process.env.MY_VAR);


3ï¸âƒ£ Get Command-Line Arguments (process.argv)
console.log("Arguments:", process.argv);
Running in Terminal > node app.js hello world

5ï¸âƒ£ Process Events (process.on())

ğŸ“Œ Handle Process Exit
```
process.on("exit", (code) => {
  console.log(`Process exited with code: ${code}`);
});
```
ğŸ‘‰ This event triggers before the process exits, allowing cleanup tasks.

ğŸ“Œ Handle Uncaught Exceptions
```
process.on("uncaughtException", (err) => {
  console.error("Uncaught Error:", err);
});
```
ğŸ‘‰ Prevents the app from crashing immediately due to unhandled errors.


6ï¸âƒ£ Exit the Process (process.exit())
```
console.log("Exiting process...");
process.exit(0); // 0 means success, any other number means error
```
ğŸ‘‰ Useful when you need to terminate the script manually.




============================================================================================================================================================


1ï¸âƒ£ How do you import and export modules in Node.js?


In Node.js, we use modules to organize code into reusable files. There are two ways to import/export modules:
1ï¸âƒ£ CommonJS (require & module.exports) â€“ Default in Node.js
2ï¸âƒ£ ES Modules (import & export) â€“ Modern approach


âœ… Use import() for lazy-loading modules dynamically.

ğŸ“Œ Which One Should You Use?
Use CommonJS if working with traditional Node.js projects.
Use ES Modules for modern projects and browser compatibility.

Execution:
(CommonJS)Synchronous (loads modules immediately)	
(ES Modules)Asynchronous (supports top-level await)

Browser Support (Where It Works):
CommonJS    :âŒ No (Node.js only)	
ES Modules  :âœ… Yes (Works in both Node.js and Browsers)


File Extension	
CommonJS:       .js	
ES Modules:     .js (with "type": "module") or .mjs


ğŸš€ Both methods allow you to create modular, reusable code in Node.js!


ğŸ”¹ 1. Using CommonJS (Default in Node.js)
âœ… Exporting with module.exports
```
function add(a, b) {
  return a + b;
}
module.exports = add;
```


âœ… Importing with require
```
const add = require("./math");
console.log(add(5, 3)); // Output: 8
```

ğŸ”¹ Exporting Multiple Values
```
module.exports = {
  add: (a, b) => a + b,
  multiply: (a, b) => a * b,
};
```

ğŸ”¹ Importing Multiple Values
```
const math = require("./math");
console.log(math.add(5, 3)); // Output: 8
console.log(math.multiply(5, 3)); // Output: 15
```




ğŸ”¹ 2. Using ES Modules (import/export)
ğŸ“ Note: ES Modules require "type": "module" in package.json


âœ… Exporting with export
```
export function add(a, b) {
  return a + b;
}
export function multiply(a, b) {
  return a * b;
}
```

âœ… Importing with import

import { add, multiply } from "./math.js";   or
import { add } from "./math.js";
console.log(add(5, 3)); // Output: 8
console.log(multiply(5, 3)); // Output: 15


ğŸ”¹ Exporting a Default Function
```
export default function add(a, b) {
  return a + b;
}
```

ğŸ”¹ Importing a Default Export
```
import add from "./math.js";
console.log(add(5, 3)); // Output: 8
```


============================================================================================================================================================



1ï¸âƒ£ How do you create a simple HTTP server in Node.js?


ğŸ“Œ Creating a Simple HTTP Server in Node.js

In Node.js, you can create an HTTP server using the built-in http module.

ğŸ”¹ Steps to Create an HTTP Server
Import the http module
Create a server with http.createServer()
Define a request handler function
Listen on a specific port using server.listen()


ğŸ”¹ Handling Different Routes
```
const http = require("http");

const server = http.createServer((req, res) => {
  res.writeHead(200, { "Content-Type": "text/html" });

  if (req.url === "/") {
    res.end("<h1>Welcome to Home Page</h1>");
  } else if (req.url === "/about") {
    res.end("<h1>About Page</h1>");
  } else {
    res.writeHead(404);
    res.end("<h1>404 Not Found</h1>");
  }
});

server.listen(3000, () => {
  console.log("Server running on http://localhost:3000");
});

```



============================================================================================================================================================



### **ğŸ“Œ Difference Between `fs.readFileSync()` and `fs.readFile()` in Node.js**  

Both methods are used to **read files** in Node.js but differ in how they handle execution.

|-----------------------------------|-----------------------------------------------|----------------------------------------------------|
| Feature                           | `fs.readFileSync()`                           | `fs.readFile()`                                    |
|-----------------------------------|-----------------------------------------------|----------------------------------------------------|
| **Execution Type**                | Synchronous (Blocking)                        | Asynchronous (Non-Blocking)                        |
| **Blocks Code Execution?**        | âœ… Yes                                        | âŒ No                                             |
| **Callback Required?**            | âŒ No                                         | âœ… Yes                                            |
| **Performance**                   | ğŸš« Slower for large files (blocks event loop) | âœ… Faster (does not block event loop)             |
| **Use Case**                      | When immediate file reading is needed         | For better performance, especially in servers      |
|-----------------------------------|-----------------------------------------------|----------------------------------------------------|



âœ… Example of fs.readFileSync() (Synchronous)
```
const fs = require("fs");
const data = fs.readFileSync("example.txt", "utf8");
console.log(data);
```
ğŸ“ Explanation:
Blocks execution until the file is read.
The next line does not execute until the file reading is complete.


âœ… Example of fs.readFile() (Asynchronous)

```
fs.readFile("example.txt", "utf8", (err, data) => {
  if (err) {
    console.error("Error reading file:", err);
    return;
  }
  console.log(data); // Output: File content
});
```

ğŸ“ Explanation:
Does not block execution.
Uses a callback function to handle the file content.



ğŸ“Œ When to Use Which?
âœ… Use fs.readFileSync()
When reading small files.
When execution must wait for file reading (e.g., configuration files).

âœ… Use fs.readFile()
When handling large files or performing multiple tasks.
For better performance, especially in web servers.

ğŸš€ For high-performance applications, always prefer fs.readFile() to avoid blocking the event loop!

============================================================================================================================================================


8ï¸âƒ£ What is middleware in Express.js?

ğŸ‘‰ So an express application is essentially nothing but a bunch of middleware functions.
ğŸ‘‰ Middleware is a function that runs before the actual route handler.
ğŸ‘‰ Middleware is basically a function that has access to the request (req), response (res) and either returns a response to the client by terminating req processig 
pipeline or passes control to another middleware function using next().
ğŸ‘‰ at runtime, when we receive a request on the server that request goes through a pipeline called "Request Processing Pipeline". In this pipeline we have one or more 
middleware functions. Each middleware function is capable of terminates the request response cycle.
ğŸ‘‰ Middleware functions are invoked in the order they are defined and are capable of modifying the request and response objects, 
as well as passing control to the next middleware function in the stack.
ğŸ‘‰ Middleware allow programmer to add functionality to the request response cycle such as authentication, logging, error handling and many more.
ğŸ‘‰ if you use lots of middleware functions inside your request processing pipeline then it will slow down your application.
ğŸ‘‰ Middleware can be defined globally, for all routes, or can be defined for specific routes or groups of routes. 
ğŸ‘‰ app.use() method is used for adding middleware function.


ğŸ”¹ Types of Middleware in Express.js
1ï¸âƒ£ Built-in Middleware â€“ Provided by Express
2ï¸âƒ£ Third-party Middleware â€“ Installed via npm
3ï¸âƒ£ Custom Middleware â€“ Created by developers


ğŸ”¹ 1. Built-in Middleware
âœ… Example: express.json() Middleware
```
app.use(express.json()); // Parses JSON request body
``` 
ğŸš€ `express.json()` middleware parses 'the JSON data' and makes it available as a 'JavaScript object' in the `req.body` property. so you don't have to manually 
parse the incoming data using `JSON.parse()`. 


âœ… Example: app.use(express.urlencoded({ extended: true }))

ğŸ‘‰ is used to parse incoming URL-encoded data from the request body and convert it into js.
ğŸ‘‰ This is used in traditional html pages where react is not used.
ğŸ‘‰ If you're submitting a React form then you typically send JSON data, not x-www-form-urlencoded. so no need to use this middleware but 
make sure to use express.json().


âœ… Example: app.use(express.static('public'));

ğŸ‘‰ It is used to serve static files (like HTML, CSS, JavaScript, images, etc.) from the "public" directory.
ğŸ‘‰ The folder does not have to be named "public". You can name it anything, but you must use the same name in express.static().
for ex: app.use(express.static("assets"));

my-app/
â”‚â”€â”€ server.js
â”‚â”€â”€ public/
â”‚   â”œâ”€â”€ index.html
â”‚   â”œâ”€â”€ styles.css
â”‚   â”œâ”€â”€ script.js
â”‚   â”œâ”€â”€ images/
â”‚       â”œâ”€â”€ logo.png

app.use(express.static("public"));   // static file are aserve from root "/"

URL                                     Serves File
--------------------------------------  ------------------------
http://localhost:3000/                  public/index.html
http://localhost:3000/styles.css        public/styles.css
http://localhost:3000/script.js         public/script.js
http://localhost:3000/images/logo.png   public/images/logo.png


ğŸ”¹ What If You Want a Custom Path?
You can serve static files from a custom URL path like /static: 
app.use("/static", express.static("public"));

Now, files must be accessed like this:
http://localhost:3000/static/styles.css
http://localhost:3000/static/images/logo.png



ğŸ”¹ 2. Third-Party Middleware

You can install middleware via npm

âœ… Example: Using morgan for Logging
```
app.use(morgan("tiny")); // Logs request details
```
ğŸš€ morgan logs every request with useful details.



ğŸ”¹ 3. Custom Middleware
You can define your own middleware
like authenticatio, logger, error


code:
```
const express = require("express");
const app = express();

function middleware(req, res, next) {
  console.log("Front Middleware");
  next();
}

function middleware1(req, res, next) {
  console.log("Middleware 1");
  next();
}

function middleware2(req, res, next) {
  console.log("Middleware 2");
  next();
}

function middleware3(req, res, next) {
  console.log("Last Middleware");
  next();
}

app.use(middleware);
app.get("/part1", [middleware1, middleware2], (req, res, next) => {
  res.send("2 middleware function : [middleware1, middleware2]");
  next();
});
app.get("/part2", middleware1, (req, res) => {
  res.send("1 middleware function: middleware1 -> we terminate req-res cycle");
});
app.use(middleware3);

const port = 5000;
app.listen(port, () => {
  console.log(`Server is listening on port ${port}`);
});

```

============================================================================================================================================================

6ï¸âƒ£ How do you handle errors in Node.js?


ğŸ”¹ 1. Using Try-Catch
```
try {
  let result = JSON.parse("invalid JSON");
} catch (error) {
  console.error("Error parsing JSON:", error.message);
}
```

ğŸ”¹ 2. Using callback
```
fs.readFile("nonexistent.txt", "utf8", (err, data) => {
  if (err) {
    console.error("File read error:", err.message);
    return;
  }
  console.log(data);
});
```

âœ… Using .catch()

```
fs.readFile("nonexistent.txt", "utf8")
  .then((data) => console.log(data))
  .catch((error) => console.error("Promise error:", error.message));
```

ğŸ”¹ 4. Global Error Handling

âœ… Handling Uncaught Exceptions
```
process.on("uncaughtException", (err) => {
  console.error("Uncaught Exception:", err.message);
  process.exit(1); // Exit the process (optional)
});
```

âœ… Handling Unhandled Promise Rejections
```
process.on("unhandledRejection", (err, promise) => {
  console.error("Unhandled Rejection:", err.message);
});
```


ğŸ”¹ Express.js Error Handling Middleware
```
const express = require("express");
const app = express();

// Middleware to simulate an error
app.get("/", (req, res, next) => {
  next(new Error("Something went wrong!"));
});

// Error handling middleware
app.use((err, req, res, next) => {
  res.status(500).json({ error: err.message });
});

app.listen(3000, () => console.log("Server running on port 3000"));
```



============================================================================================================================================================



9ï¸âƒ£ How can you handle file uploads in Node.js?

ğŸ“Œ Handling File Uploads in Node.js
To handle file uploads in a Node.js application, we typically use multer, a popular middleware for handling multipart/form-data in Express.


Multer is a node.js middleware for handling multipart/form-data, which is primarily used for uploading files. 
NOTE: Multer will not process any form which is not multipart (multipart/form-data).


Normal File Upload: 

ğŸ”¹ Allowed File Types with Your Code:
âœ… Images (.jpg, .jpeg, .png, .gif, .svg, .webp)
âœ… Documents (.pdf, .doc, .docx, .txt)
âœ… Spreadsheets (.xls, .xlsx, .csv)
âœ… Videos (.mp4, .avi, .mov)
âœ… Audio Files (.mp3, .wav)
âœ… Other Files (.zip, .rar, .json, .xml)


ğŸš€ storage: 
If you want more control over your uploads, you'll want to use the "storage" option instead of "dest".
Multer ships with storage engines "DiskStorage" and "MemoryStorage"; More engines are available from third parties.


### **ğŸ¯ When to Use Which?**
|-----------------------------------|-----------------------------------------------|----------------------------------------------------------------------------|
| Storage Engine                    | `diskStorage`                                 | `memoryStorage`                                                            |
|-----------------------------------|-----------------------------------------------|----------------------------------------------------------------------------|
| **Where files are stored?**       | Saves files to disk (filesystem)              | Stores files in memory (RAM) as a `Buffer`                                 |
| **How files are accessed?**       | Stored in a specific directory                | Stored in `req.file.buffer` as binary data                                 |
| **Use Case**                      | When you need to save files permanently       | When you need to process files immediately                                 |
| **Performance**                   | Slightly slower (writes to disk)              | Faster (stored in RAM, no disk I/O)                                        |
| **Example Use Cases**             | Uploading profile pictures, saving documents  | Image processing, sending files to cloud storage (e.g., AWS S3, Cloudinary)|
|-----------------------------------|-----------------------------------------------|----------------------------------------------------------------------------|



1ï¸âƒ£. DiskStorage
-> The disk storage engine gives you full control on storing files to disk.
code: 
```
const storage = multer.diskStorage({
    destination: function(req, file, cb){
        cb(null, 'uploads/')
    },
    filename: function(req, file, cb){
        cb(null, file.originalname)
    }
})
const upload = multer({ storage: storage })
```

There are two options available, "destination" and "filename". 
They are both functions that determine where the file should be stored.

"destination": destination is used to determine within which folder the uploaded files should be stored. 
This can also be given as a string (e.g. '/tmp/uploads'). If no destination is given, the operating system's default directory for temporary files is used.

"filename": filename is used to determine what the file should be named inside the folder. If no filename is given, each file will be given a random name that 
doesn't include any file extension.
Note: Multer will not append any file extension for you, your function should return a filename complete with an file extension.



2ï¸âƒ£ MemoryStorage: 
The memory storage engine stores the files in memory as Buffer objects. It doesn't have any options.
```
const storage = multer.memoryStorage()
const upload = multer({ storage: storage })
```
When using memoryStorage, the uploaded file is not saved to disk but stored in RAM as a buffer inside req.file.buffer. 
You can access it and perform operations like processing, uploading to cloud storage, or converting the file.
If you're uploading files to Cloudinary (or any cloud storage like AWS S3, Firebase, etc.), you should use memoryStorage in Multer.




How to Use multipart/form-data in Postman for File Uploads?
1ï¸âƒ£ Open Postman and Create a POST Request
Method: POST
URL: http://localhost:3000/customer (or your API endpoint)


2ï¸âƒ£ Select Body Tab
Click on Body.

Select "form-data".

Now add your fields:

---------------------------------
Key	        Value	        Type
---------------------------------
name	    John Doe	    Text
profilePic	(Select file)	File
---------------------------------

For text fields: Select Text from the dropdown.
For file upload: Select File and choose a file from your system


3ï¸âƒ£ Send the Request
Click Send.
Your API should receive:
```
req.body: { name: "John Doe" }
req.file: { originalname: "myphoto.jpg", mimetype: "image/jpeg", path: "uploads/myphoto.jpg" }
```


4ï¸âƒ£ Verify req.body and req.file in Your Express App
If req.body is undefined, make sure you have added:
```
app.use(express.json());
```




final Example : 

```

const express = require('express');
const app = express();
const multer = require('multer');
 const storage = multer.diskStorage({
     destination: function(req, file, cb){
         cb(null, 'uploads/')
     },
     filename: function(req, file, cb){
         cb(null, file.originalname)
     }
 }); // use it if you want to keep files on server file system

const storage = multer.memoryStorage();  // use it for uploading images on cloudinary, aws
// const upload = multer({ dest: 'uploads/' });  // simple
const upload = multer({ storage: storage });



app.use(express.json()); // Enable JSON parsing (if needed)\

// accepting single file from input name 'profilePic'
app.post('/api/upload', upload.single('profilePic'), (req, res) => {
    const file = req.file;
    return res.status(201).json({ file })
});


// accepting multiple file from input name 'photos' with maximum upload limit of 5
app.post('/api/photos/upload', upload.array('photos', 5), (req ,res) => {
    const photos = req.files;
    return res.status(201).json({ photos })
});


// accepting multiple files from different input fields having names ('avatar', 'gallery')
const cpUpload = upload.fields([{ name: 'avatar', maxCount: 1}, { name: 'gallery', maxCount: 5}])
app.post('/cool-profile', cpUpload, (req, res) => {
    const files = req.files;
    return res.status(201).json({ files });
});


// select profileImage along with data.
// go to postman, Select Body Tab, Select form-data, Now add your fields: name, age, profilePic
// For text fields: Select Text from the dropdown. For file upload: Select File and choose a file from your system.
app.post('/api/customer', upload.single('profilePic'), (req, res) => {
    console.log('file', req.file);  // âœ… Works fine
    console.log('body', req.body);  // âœ… Should now contain text fields
    return res.status(201).json({ file: req.file, body: req.body });
});


app.listen(5000, () => {
    console.log(`server listning on port 5000`);
})

```








============================================================================================================================================================


3ï¸âƒ£ What is Buffer in Node.js?

A Buffer in Node.js is a built-in class that allows "handling binary data directly in memory". 
It is useful for "processing" files, network packets, or raw binary streams.


ğŸ”¹ Why Use Buffer?
âœ… Handles binary data (images, videos, etc.)
âœ… Works without a string encoding format
âœ… Efficiently manipulates raw data in memory


âœ… Creating a Buffer
```
const buf = Buffer.alloc(10); // Creates a buffer of 10 bytes (filled with zeros)
console.log(buf); // <Buffer 00 00 00 00 00 00 00 00 00 00>
```

âœ… Creating a Buffer from Data
const buf = Buffer.from('Hello')
console.log(buf); // <Buffer 48 65 6c 6c 6f>
console.log(buf.toString()); // "Hello"


âœ… Writing to a Buffer
buf.write("Node.js");
console.log(buf.toString()); // "Node.js"


âœ… Reading Buffer Data
const buf = Buffer.from("ABC");
console.log(buf[0]); // 65 (ASCII code of 'A')
console.log(buf[1]); // 66 ('B')
console.log(buf[2]); // 67 ('C')



============================================================================================================================================================


3ï¸âƒ£ How do you handle command-line arguments in a Node.js script?

ğŸ“Œ Handling Command-Line Arguments in Node.js
In Node.js, you can handle command-line arguments using the "process.argv" array or third-party packages like "yargs" and "commander".

ğŸ”¹ 1. Using process.argv (Built-in)
The process.argv array contains command-line arguments passed to the Node.js script.

âœ… Example
// script.js
console.log(process.argv);
Run the script:

node script.js arg1 arg2
Output:
[
  'C:\\Program Files\\nodejs\\node.exe', // Node.js path
  'C:\\Users\\User\\script.js',         // Script path
  'arg1',                               
  'arg2'
]
ğŸ“Œ The first two elements are always:
1ï¸âƒ£ Path to the Node.js executable
2ï¸âƒ£ Path to the script being executed
3ï¸âƒ£ Arguments start from index 2

âœ… Accessing Arguments

const args = process.argv.slice(2); // Remove first two elements
console.log("Arguments:", args);
Run:
```
node script.js hello world
```

Output:
Arguments: [ 'hello', 'world' ]





============================================================================================================================================================


ğŸ“Œ Difference Between __dirname and __filename in Node.js

Both __dirname and __filename are global variables in Node.js that provide information about the current script's location.


## **ğŸ”¹ Global Variables (NOT Global Objects)**
|-------------------|----------------------------------------------------------------|
| Global Variable   | Description                                                    |
|-------------------|----------------------------------------------------------------|
| `__dirname`       | Returns the **absolute directory path** of the current script. |
| `__filename`      | Returns the **absolute file path** of the current script.      |
|-------------------|----------------------------------------------------------------|




2ï¸âƒ£ __dirname (Current Directory Path)
console.log(__dirname); // Example: /home/user/project

3ï¸âƒ£ __filename (Current File Path)
console.log(__filename); // Example: /home/user/project/index.js


============================================================================================================================================================



### **ğŸ“Œ Difference Between Absolute Path and Relative Path**  

|-------------------|----------------------------------------------------------------------------|
| Type              | Description                                                                |   
|-------------------|----------------------------------------------------------------------------|
| **Absolute Path** | The full path from the **root directory** to a file or folder.             |
| **Relative Path** | The path **relative** to the current working directory or script location. |
|-------------------|----------------------------------------------------------------------------|

---

ğŸ”¹ Absolute Path
âœ… Always starts from the root (`/` in Linux/macOS, `C:\` in Windows)  
âœ… Same path regardless of where the script is executed  

ğŸ”¹ Example:
- Windows: `C:\Users\John\Documents\file.txt`

âœ… Example in Node.js
```
const path = require("path");

console.log(path.resolve("file.txt"));// Absolute path example
```
Output (depends on where you run it):
```
C:\Users\John\project\file.txt  (Windows)
```

---

ğŸ”¹ Relative Path
âœ… Depends on the current working directory (`cwd`)  
âœ… Shorter and flexible  

ğŸ”¹ Example:  
- `./file.txt` â†’ Refers to `file.txt` in the **current folder**  
- `../file.txt` â†’ Moves **one directory up** before looking for `file.txt`  

âœ… Example in Node.js
```js
const path = require("path");

// Relative path
console.log(path.join(__dirname, "file.txt"));
```
ğŸ“Œ `__dirname` helps resolve relative paths safely.

---

### ğŸ“Œ Key Differences**
|---------------------------|-------------------------------|--------------------|
| Feature                   | Absolute Path                 | Relative Path      |
|---------------------------|-------------------------------|--------------------|
| Starts from?              | Root directory (`C:\`, `/`)   | Current directory  |
| Changes with location?    | âŒ No                         | âœ… Yes            |
| Example (Windows)         | `C:\Users\John\file.txt`      | `./file.txt`       |
|---------------------------|-------------------------------|--------------------|

ğŸš€ **Use absolute paths when you need a fixed location, and relative paths for flexibility!**






============================================================================================================================================================



ğŸ“Œ Debugging a Node.js Application in Development & Production:




ğŸ”¹ Debugging in Development


1ï¸âƒ£ Using console.log() (Basic Debugging)

console.log("User Data:", user);


4ï¸âƒ£ Using VS Code Debugger

Open your project in VS Code.
Go to Run & Debug (Ctrl + Shift + D).
Click "create launch.json file" â†’ Select "Node" -> then delete everything inside "configurations" array and type "cmd" and enter first suggestion 
"Run npm start in a debug terminal". then inside "command" property add "npm run dev" then click on "Run npm start" button in top left panal

ex: launch.json file:
{
    "version": "0.2.0",
    "configurations": [
        {
            "command": "npm run dev",
            "name": "Run npm start",
            "request": "launch",
            "type": "node-terminal"
        }
    ]
}





ğŸ”¹ Debugging in Production:


1ï¸âƒ£ Using winston for Logging
3ï¸âƒ£ Using Error Tracking (e.g., Sentry)



============================================================================================================================================================


3ï¸âƒ£ How do you use environment variables in a Node.js application?


Environment variables store configuration settings (like database credentials, API keys) outside your code, making apps more secure and flexible.


ğŸ”¹ 1ï¸âƒ£ Accessing Environment Variables
Node.js provides process.env to access environment variables inside a code.

âœ… Example:
console.log(process.env.NODE_ENV); // Output: development (if set)
console.log(process.env.PORT);     // Output: 5000 (if set)


There are multiples ways thjaty you can pass environmental variables.

ğŸ”¹ 2ï¸âƒ£ Setting Environment Variables

âœ… Temporary (Command Line)

Windows (PowerShell): 
```
PS C:\Users\user\Desktop\ooo> $env:PORT=8000; node .\server.js
```

ğŸ“Œ These are temporary and reset after the terminal closes


3ï¸âƒ£ Using a .env File (Best Practice)
Using a .env file makes configuration easier.
âœ… Step 1: Install dotenv


ğŸ”¹ 4ï¸âƒ£ Setting Environment Variables in package.json (Scripts)
Define variables in package.json scripts.
```
"scripts": {
  "start": "NODE_ENV=production node index.js"
}
```


============================================================================================================================================================



1ï¸âƒ£  Explain the difference between process.nextTick() and setImmediate().

Both process.nextTick() and setImmediate() schedule callbacks to execute asynchronously, but they have key differences in execution order.

ğŸ“Œ process.nextTick() Has higher priority than setImmediate().
ğŸ“Œ process.nextTick() executes before setImmediate().


âœ… Example:
```
console.log("Start");

setImmediate(() => console.log("Executed in setImmediate"));
process.nextTick(() => console.log("Executed in process.nextTick"));

console.log("End");
```

ğŸ“ Output:
```
Start
End
Executed in process.nextTick
Executed in setImmediate
```


## **ğŸ”¹ 4ï¸âƒ£ When to Use?**
|---------------------- |-----------------------------------------------|----------------------------------         |
| Feature               | `process.nextTick()`                          | `setImmediate()`                          |        
|---------------------- |-----------------------------------------------|----------------------------------         |
| **Execution Timing**  | Before the event loop continues               | In the next event loop iteration          |
| **Priority**          | Higher (executes before I/O)                  | Lower (executes after I/O)                |
| **Use Case**          | For critical operations that must run ASAP    | For executing code after I/O operations   |
|---------------------- |-----------------------------------------------|----------------------------------         |



============================================================================================================================================================


â“ Streams in Node.js:


ğŸ‘‰ Streams in Node.js are used to 'handle large amounts of data' efficiently by 'processing it chunk by chunk', instead of loading everything into memory at once.

ğŸ‘‰ With streams, instead of loading the entire file into memory at once, you load it chunk by chunk, process it, and then discard it before loading the next chunk. 
This means:
Without streams: The entire file is loaded into RAM, which can be problematic for large files (e.g., a 5GB video).
With streams: Only small chunks (e.g., 64KB) are loaded into memory at a time, processed, and then discarded before the next chunk arrives.
This reduces memory usage and allows Node.js to handle large files efficiently without exhausting system resources.


ğŸ‘‰ Streams in Node.js can handle any type of data that can be processed in chunks. This includes:

1. Text files (.txt, .csv, .json, etc.) â€“ Read and process line by line instead of loading the entire file into memory.

2. DOCX, PDF, and other document files â€“ Useful for generating or modifying documents without reading the whole file into memory.

3. Images (.jpg, .png, etc.) â€“ Streams are used for image uploads, processing, and compression.

4. Videos and audio (.mp4, .mp3, .wav, etc.) â€“ Essential for streaming services where loading an entire video/audio file would be inefficient.

5. Binary files (.zip, .tar, etc.) â€“ Streams can help process large compressed files efficiently.

6. Network data (HTTP requests, WebSockets, etc.) â€“ Handling real-time data, such as uploading or downloading large files.

7. Database operations â€“ Some databases support streaming large query results instead of returning everything at once.

So, Node.js streams are not limited to text files; they can handle any type of data that can be processed in chunks.



ğŸ“Œ Why use streams?
âœ” Faster than 'traditional I/O operations' like fs.readFile(), fs.writeFile() etc.
âœ” Efficient for large files (e.g., reading/writing logs, video streaming).
âœ” Memory-efficient (processes chunks instead of entire data).
âœ” Doesnâ€™t load the full file into memory.
âœ” Processes data as it arrives and then discard it before loading the next chunk.


|-----------------|---------------------------------------------------------------------|
| Stream Type     | Function                                                            |
|-----------------|---------------------------------------------------------------------|
| Readable        | Read data from a source (e.g., file, API, socket).                  |
| Writable        | Write data to a destination (e.g., file, response).                 |
| Duplex          | Read and write simultaneously (e.g., network sockets).              |
| Transform       | Modify data while reading/writing (e.g., compression, encryption).  |
|-----------------|---------------------------------------------------------------------|


ğŸ”¹ 1ï¸âƒ£ Readable Stream (Reading Data)
A Readable Stream allows data to be read in chunks.


```
const fs = require("fs");

const readableStream = fs.createReadStream("example.txt", "utf-8");

readableStream.on("data", (chunk) => {
  console.log("Received chunk:", chunk);
});

```

ğŸ”¹ 2ï¸âƒ£ Writable Stream (Writing Data)

A Writable Stream writes data in chunks.

```
const fs = require("fs");

const writableStream = fs.createWriteStream("output.txt");

writableStream.write("Hello, ");
writableStream.write("world!");
writableStream.end(); 
```

ğŸ”¹ 3ï¸âƒ£ Duplex Stream (Read & Write)

A Duplex Stream can both read and write data.

```
const { Duplex } = require("stream");

const duplexStream = new Duplex({
  read(size) {
    this.push("Hello from Duplex Stream!");
    this.push(null);
  },
  write(chunk, encoding, callback) {
    console.log("Writable received:", chunk.toString());
    callback();
  },
});

duplexStream.on("data", (chunk) => console.log("Readable output:", chunk.toString()));

duplexStream.write("Sending data");
duplexStream.end();

```



ğŸ”¹ 4ï¸âƒ£ Transform Stream (Modifies Data)

A Transform Stream is a Duplex Stream that modifies data before passing it.


```
const { Transform } = require("stream");

const transformStream = new Transform({
  transform(chunk, encoding, callback) {
    this.push(chunk.toString().toUpperCase()); // Convert data to uppercase
    callback();
  },
});

process.stdin.pipe(transformStream).pipe(process.stdout);

```

============================================================================================================================================================

â“ How do you handle large file uploads efficiently in Node.js?

 ğŸ‘‰
 
 Uploading large files in Node.js can be challenging due to memory constraints. Instead of loading the entire file into memory, we use streaming and chunked uploads to handle large files efficiently.

Best Practices for Handling Large File Uploads
âœ… Use Streaming â€“ Process files in chunks instead of loading them into memory.
âœ… Use Multer or Busboy â€“ Middleware for handling file uploads.
âœ… Store Files in Cloud Storage â€“ Use Cloudinary, AWS S3, or Firebase instead of storing them locally.
âœ… Enable Chunked Uploads â€“ Upload files in parts and merge them.
âœ… Use Nginx as a Reverse Proxy â€“ Optimize request handling before reaching Node.js.



1ï¸âƒ£ Streaming Uploads Using Multer + Streams

```
const express = require('express');
const multer = require('multer');
const fs = require('fs');

const app = express();
const upload = multer({ dest: 'uploads/' }); // Temporary storage

app.post('/upload', upload.single('file'), (req, res) => {
  const file = req.file;
  const readStream = fs.createReadStream(file.path);
  const writeStream = fs.createWriteStream(`uploads/${file.originalname}`);

  readStream.pipe(writeStream);

  writeStream.on('finish', () => {
    res.send({ message: 'File uploaded successfully!' });
  });

  writeStream.on('error', (err) => {
    res.status(500).send({ error: 'File upload failed!' });
  });
});

app.listen(3000, () => console.log('Server running on port 3000'));
```


2ï¸âƒ£ Uploading Directly to Cloud Storage (e.g., AWS S3)


```
const AWS = require('aws-sdk');
const multer = require('multer');
const multerS3 = require('multer-s3');
const express = require('express');

const app = express();
const s3 = new AWS.S3({ region: 'us-east-1' });

const upload = multer({
  storage: multerS3({
    s3,
    bucket: 'my-bucket-name',
    key: (req, file, cb) => cb(null, file.originalname)
  })
});

app.post('/upload', upload.single('file'), (req, res) => {
  res.send({ message: 'File uploaded to S3 successfully!' });
});

app.listen(3000, () => console.log('Server running on port 3000'));

```
============================================================================================================================================================


ğŸ“Œ What is child_process?

ğŸ”¹ child_process Module in Node.js

The 'child_process module' allows us to create and manage 'child processes' in Node.js. 

This is useful for:

âœ” Executing system commands (e.g., running shell commands)
âœ” Spawning new Node.js processes
âœ” Running CPU-intensive tasks asynchronously
âœ” Executing scripts in different languages (Python, Bash, etc.)

---

ğŸ”¹ Ways to Create Child Processes**  
The `child_process` module provides four main methods:  

| Method | Description | Output Type |
|--------|------------|------------|
| `spawn()` | Used for streaming large output (handles I/O as streams) | Stream |
| `exec()` | Used for small outputs (buffers the entire output) | Buffer (string) |
| `execFile()` | Like `exec()`, but runs a file directly | Buffer (string) |
| `fork()` | Used to create a separate Node.js process (for IPC) | Dedicated Node.js process |

---

## ğŸ”¹ 1ï¸âƒ£ `spawn()` - Used for Streaming Large Output
âœ… Best for handling large amounts of data (does not buffer).  
âœ… Returns a stream, so it processes data chunk by chunk.  

### âœ… Example: Running a Shell Command (`ls -l` or `dir` on Windows)
```js
const { spawn } = require("child_process");

const ls = spawn("ls", ["-l"]); // Use "dir" for Windows

ls.stdout.on("data", (data) => {
  console.log(`Output: ${data}`);
});

ls.stderr.on("data", (data) => {
  console.error(`Error: ${data}`);
});

ls.on("close", (code) => {
  console.log(`Process exited with code ${code}`);
});
```
ğŸ“Œ Use Case: When you need real-time output (e.g., logging, data streaming).  

---

## ğŸ”¹ 2ï¸âƒ£ `exec()` - Runs a Command and Buffers Output
âœ… Best for commands with small output  
âœ… Buffers entire output before returning  

### âœ… Example: Running a Command (`ls -l`)
```js
const { exec } = require("child_process");

exec("ls -l", (error, stdout, stderr) => {
  if (error) {
    console.error(`Error: ${error.message}`);
    return;
  }
  if (stderr) {
    console.error(`Stderr: ${stderr}`);
    return;
  }
  console.log(`Output:\n${stdout}`);
});
```
ğŸ“Œ Use Case: When you don't need streaming and expect small output.  

---

## ğŸ”¹ 3ï¸âƒ£ `execFile()` - Runs an Executable File Directly
âœ… Similar to `exec()`, but runs an executable file directly.  

### âœ… Example: Running a Python Script
```js
const { execFile } = require("child_process");

execFile("python", ["script.py"], (error, stdout, stderr) => {
  if (error) {
    console.error(`Error: ${error.message}`);
    return;
  }
  console.log(`Output: ${stdout}`);
});
```
ğŸ“Œ Use Case: Running external executables like Python scripts or binaries.  

---

## **ğŸ”¹ 4ï¸âƒ£ `fork()` - Spawning a New Node.js Process**
âœ… Best for running another Node.js script as a child process  
âœ… Supports Inter-Process Communication (IPC)  

### âœ… Example: Forking a Child Node.js Process
#### ğŸ“Œ `child.js` (Child Process)
```js
process.on("message", (msg) => {
  console.log(`Child received: ${msg}`);
  process.send("Hello from Child");
});
```
#### ğŸ“Œ `parent.js` (Main Process)
```js
const { fork } = require("child_process");

const child = fork("child.js");

child.send("Hello from Parent");

child.on("message", (msg) => {
  console.log(`Parent received: ${msg}`);
});
```
ğŸ“Œ **Use Case:** Running a separate Node.js script in a new process (e.g., parallel tasks).  

---

## **ğŸ”¹ Summary**
| Method | Best For | Output |
|--------|---------|--------|
| `spawn()` | Large data streaming (real-time output) | **Stream** |
| `exec()` | Small output (buffers entire output) | **Buffer (string)** |
| `execFile()` | Running executable files directly | **Buffer (string)** |
| `fork()` | Running another Node.js script as a child process | **Dedicated Node.js process** |

ğŸš€ **Conclusion:**  
The `child_process` module is powerful for executing system commands, running scripts, and handling background processes.













============================================================================================================================================================


6ï¸âƒ£ What is rate limiting, and how do you implement it in Node.js?

Rate limiting is a technique used to control the number of requests a user can make to a server within a specific time period.  

It helps to:  
âœ… Prevent API abuse (e.g., bots, DDoS attacks).  
âœ… Protect server resources (avoid overload).  
âœ… Ensure fair usage (limit per user/IP).  


If they exceed the limit, they get an HTTP 429 Too Many Requests error.


ğŸ”¹ How to Implement Rate Limiting in Node.js using express-rate-limit package?

1ï¸âƒ£ Using `express-rate-limit` (for Express.js apps)
However, this doesn't work well in distributed systems where multiple servers handle requests.


ğŸ”¹ Where is Rate Limiting Used?
âœ… Login attempts: Prevent brute-force attacks.  
âœ… API requests: Protect backend servers from overload.  
âœ… Search queries: Avoid excessive requests from bots.  
âœ… File uploads: Control how many files a user can upload in a short time.


ğŸ”¹ How to Implement Rate Limiting in Node.js using redis?

ğŸ’¡ Redis is the best choice for rate limiting because it is:
âœ… Fast (stores data in RAM).
âœ… Persistent across multiple servers (unlike in-memory solutions).





============================================================================================================================================================





============================================================================================================================================================



















































































































































































