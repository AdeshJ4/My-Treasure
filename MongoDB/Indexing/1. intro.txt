Indexes: Retrieving data efficently

ðŸ“Œ Indexes are most effective when they significantly reduce the number of documents MongoDB needs to retrieve.

In MongoDB, an index is a data structure that improves the speed of data retrieval operations on a collection.
Speeds up queries by reducing the number of documents MongoDB needs to scan

Indexes speed up find, update, and delete queries by reducing the number of documents MongoDB needs to scan that means basically Index on field Helps find the documents
quickly but the Problem: is the actual update/delete operation still takes time.
MongoDB update/delete every matching document individually, which is slow.

Without indexes, MongoDB must scan every document in a collection to return query results
Although indexes improve query performance, adding an index has negative performance impact for write operations. 
For collections with a high write-to-read ratio, indexes are expensive because each insert must also update any indexes.

============================================================================================================================================================

âš ï¸ When Indexes Donâ€™t Help (With Examples):

âŒ 1ï¸âƒ£Indexes Wonâ€™t Help If a Query Uses $regex (Without Prefix)
ðŸ”¹ Example ($regex Without a Prefix)
db.users.find({ name: { $regex: "esh", $options: "i" } });
Scenario: Searching for users where "esh" appears anywhere in the name.
Problem: âŒ Index wonâ€™t be used because MongoDB must scan the entire collection to find matches.
Why? Indexes only work well if you search from the beginning (/^pattern/).
âœ… Solution:
db.users.find({ name: { $regex: /^Adesh/i } });
âœ” Uses the index because it searches from the start.

âŒ 2ï¸âƒ£ Indexes Wonâ€™t Help When Filtering on a Low-Cardinality Field
ðŸ”¹ Example (Boolean Fields)
db.users.find({ isActive: true });
Scenario: Index on isActive (true/false).
Problem: âŒ If 90% of documents have isActive: true, MongoDB still scans most of the collection.
Why? Indexes are useful only when they significantly reduce the number of scanned documents.
âœ… Solution: Use an index on a more selective field (e.g., lastLoginDate).


âŒ 3ï¸âƒ£ Indexes Wonâ€™t Help If a Query Uses $or on Unindexed Fields
ðŸ”¹ Example ($or Without Indexes)
db.orders.find({ 
    $or: [{ status: "shipped" }, { totalPrice: { $gt: 1000 } }] 
});
Scenario: No index on status or totalPrice.
Problem: âŒ MongoDB performs a full collection scan.
Why? It can't efficiently use indexes with $or unless both fields are indexed.
âœ… Solution:
Create compound index: { status: 1, totalPrice: 1 }
Rewrite query: Use separate indexed queries instead of $or

============================================================================================================================================================


ðŸ“Œ How Indexes Improve Performance:

1ï¸âƒ£find Queries (Read Operations)

Indexes allow MongoDB to quickly locate documents without scanning the entire collection.
Example:
db.users.createIndex({ name: 1 }); // Index on "name" field
db.users.find({ name: "Adesh" }); // Uses index for fast lookup

============================================================================================================================================================



In MongoDB, there are three main types of scans** used to retrieve data:  

1. Index Scan (`IXSCAN`) âœ… (Fastest)  
2. Collection Scan (`COLLSCAN`) âŒ (Slowest)  
3. Covered Query (`COVEREDIXSCAN`) ðŸ”¥ (Fastest & Most Efficient)  

---

 1ï¸âƒ£ Index Scan (`IXSCAN`) âœ… (Fast)
- What is 
  - MongoDB uses an index to find the required documents instead of scanning the whole collection.  
- When does it happen?  
  - When you query a **field that has an index.  
- Performance:  
  - Much faster** than a full collection scan.  

ðŸ”¹ Example:  
db.users.createIndex({ name: 1 }); // Create an index on "name"
db.users.find({ name: "Adesh" });  // Uses index (IXSCAN)
ðŸ”¹ Query Plan (`explain()` output):  
"stage": "IXSCAN"
âœ… Uses the index efficiently to fetch matching documents.  


 2ï¸âƒ£ Collection Scan (`COLLSCAN`) âŒ (Slow)
- What is it?  
  - MongoDB scans every document in the collection **because no suitable index exists**.  
- When does it happen?  
  - When a query doesnâ€™t use an index.  
- Performance 
  - Very slow for large datasets (not recommended).  
ðŸ”¹ Example (No Index):  
db.users.find({ age: 25 }); // No index on "age", triggers COLLSCAN
ðŸ”¹ Query Plan (`explain()` output):  
"stage": "COLLSCAN"
âŒ Avoid collection scans for large datasetsâ€”they are slow and inefficient.
âœ… Solution: Create an index:  
db.users.createIndex({ age: 1 });


 3ï¸âƒ£ Covered Query (`COVEREDIXSCAN`) ðŸ”¥ (Fastest & Most Efficient)
- What is it?  
  - A query is fully satisfied** by an index without needing to fetch documents from the collection.
  - all filds are index fileds  
- When does it happen?  
  - When all queried fields (filter + projection) are present in an index**.  
- Performance:  
  - Faster than `IXSCAN`, as it avoids accessing the actual documents**.  
ðŸ”¹ **Example:  
db.users.createIndex({ name: 1, age: 1 }); // Compound index
db.users.find({ name: "Adesh" }, { age: 1, _id: 0 }); // Covered Query
ðŸ”¹ Query Plan (`explain()` output):  
"stage": "COVEREDIXSCAN"
âœ… Fastest query type! ðŸš€




============================================================================================================================================================



1. create Index: 
playGround> db.person.createIndex({"dob.age": 1})
> dob.age_1  // name of index
1: ascending order
0: descending order
Note: You can create index on nested field.

2. get Indexes
db.users.getIndexes()
[
  { v: 2, key: { _id: 1 }, name: '_id_' },
  { v: 2, key: { 'dob.age': 1 }, name: 'dob.age_1' }
]
_id field have by default index on it.

3. drop index
myDB> db.users.dropIndex('dob.age_1')
{ nIndexesWas: 2, ok: 1 } 




============================================================================================================================================================


MongoDB Query Execution Without and With Indexes  

 1ï¸âƒ£ Query Without an Index (`COLLSCAN`)  
- Query:  
  db.products.find({ seller: "Max" })

- If there is no index on the `seller` field, MongoDB will perform a **Collection Scan (`COLLSCAN`).  
- What happens during a `COLLSCAN`?  
  - MongoDB scans every document in the collection one by one to find matches.  
  - This slows down performanc* if the collection is large.  
- Problem:  
  - Imagine a collection with millions of document*â€”the query would take a long time to execute.  

---

2ï¸âƒ£ Creating an Index on `seller` Field
- Indexes are an addition, not a replacement for the collection.  
- When you create an index on the `seller` field, MongoDB stores this index separately from the collection.  
- How does an index work?  
  - The index acts like an ordered list of all values in the `seller` field.  
  -Example (Index for `seller` field):  
    Seller Index -> | Anna | Chris | Manu | Max | Max | Zod | .... 
    
  - This index is **sorted** and includes a pointer to each corresponding document.  

âœ… Index Creation Example:  
db.products.createIndex({ seller: 1 });

---

3ï¸âƒ£ Query With an Index (`IXSCAN`)  
- Now, when you run the query:  
  db.products.find({ seller: "Max" })

  MongoDB uses an Index Scan (`IXSCAN`) instead of scanning the entire collection.  
- How does `IXSCAN` work?**  
  - MongoDB jumps directly to the sorted index and quickly finds `"Max"`.  
  - Since the index is already sorted, MongoDB **does not need to scan all documents** before reaching `"Max"`.  
  - Faster lookup compared to `COLLSCAN`.  

âœ… Conclusion: 
- Without an index â†’ Full collection scan (`COLLSCAN`) â†’ Slow for large datasets.  
- With an index â†’ Index scan (`IXSCAN`) â†’ Faster and more efficient.  


============================================================================================================================================================



âš ï¸ Avoid Creating Too Many Indexes**  

 1ï¸âƒ£ Indexes Improve `find` Queries but Slow Down `insert` Operations 
- Indexes **speed up `find` queries**, making searches much faster.  
- However, **they slow down `insert`, `update`, and `delete` operations** because MongoDB needs to **update all relevant indexes** whenever a document is modified.  

---

2ï¸âƒ£ How Indexes Affect Inserts, Updates & Deletes*
- An index is an ordered list of values with pointers to the documents.  
- Whenever a new document is inserted:  
  - MongoDB must update every index associated with that collection.  
  - This can **increase write operation time** significantly.  
- If you have 10 indexes on a collection:  
  - Each `insert`, `update`, or `delete` operation must update all 10 indexes.  
  - This results in performance overhead and increased storage usage.  

---

3ï¸âƒ£ Choosing the Right Fields for Indexing 
- Not every field needs an index**â€”only **frequently searched fields** should be indexed.  
- Too many indexes **consume extra disk space** and **slow down write operations**.  
- Best Practice:  
  - Analyze queries with **`explain()`** to see **which fields need indexing**.  
  - Prioritize indexes for **fields used in filtering, sorting, and joins (`$lookup`)**.  

âœ… **Conclusion:**  
- **Use indexes wisely**â€”don't index every field.  
- **Too many indexes slow down `insert`, `update`, and `delete`** queries.  
- **Optimize indexing** based on query patterns and performance needs.  



============================================================================================================================================================



explain(): 
====================
MongoDB gives us a tool to analyze how it executed the query and this tool is a simple method we add to our query.
explain() works for find(), update(), delete() and not for insert().

explain() method takes following arguments:
1. queryPlanner: Show summary for Executed Query + Winning Plan
2. executionStats: Show Detailed Summary for Executed Query + Winning Plan + possibly rejected plans
3. allPlansExecution: Show Detailed Summary for Executed Query + Winning Plan + Winning plan Decision Process

playGround> db.person.explain("executionStats").find({"dob.age": {$gt: 60}})

check "executionStats", "winningPlan" field 


without Index: 
db.person.explain("executionStats").find({"dob.age": {$gt: 60}})
>executionStats: {
    executionSuccess: true,
    nReturned: 1222,
    executionTimeMillis: 5,  <--------- Time
    totalKeysExamined: 0,
    totalDocsExamined: 5000,
    executionStages: {
      stage: 'COLLSCAN',  <-------------- Collection Scan
    }
  },

with Index: 
db.person.explain("executionStats").find({"dob.age": {$gt: 60}})
>executionStats: {
    executionSuccess: true,
    nReturned: 1222,
    executionTimeMillis: 3,  <-------------------------Time
    totalKeysExamined: 1222,
    totalDocsExamined: 1222,
    executionStages: {
      stage: 'FETCH',
      nReturned: 1222,
      inputStage: {
        stage: 'IXSCAN',  <---------------------Index scan
      }
    }
}


============================================================================================================================================================



ðŸ“Œ Understanding When Indexes Help & When They Donâ€™t
1ï¸âƒ£ How Indexes Work in MongoDB
âœ… When an index is used, MongoDB follows these steps:
Scans the index to find matching keys.
Retrieves documents from the collection using pointers.
This process involves an extra step (reading the index first and then fetching documents).
ðŸ“Œ Indexes are most effective when they significantly reduce the number of documents MongoDB needs to retrieve.
Example: If only 5 out of 5000 documents match age > 20, the index drastically reduces the work.

2ï¸âƒ£ Collection Scan (COLLSCAN) Behavior
âœ… COLLSCAN reads data sequentially from disk or memory.
If the entire collection fits in memory, a COLLSCAN can be fast, as MongoDB reads documents directly in sequence.

ðŸ“Œ When Indexes May Be Slower

If a query returns a large portion (or the majority) of the documents, an index can actually slow down the query.
MongoDB first scans the index.
Then, it retrieves all matching documents from the collection.
This adds an extra step, making it inefficient.
Example: If a query returns 90% of the documents, using an index is wastefulâ€”a direct COLLSCAN would be better.
ðŸ“Œ When Indexes Are Useful

If a query returns only 10â€“20% of the dataset, indexes significantly improve performance.
Ideal for targeted searches like:
db.users.find({ age: { $gt: 30 } }) // Small subset of data
3ï¸âƒ£ Indexing Different Data Types
âœ… You can create indexes on fields containing text, numbers, or other searchable values.
âŒ Boolean fields (true/false) do not benefit much from indexing since they have only two possible values.

âœ… Conclusion:

Indexes improve targeted queries but may slow down queries that retrieve most or all of the documents.
Use indexes for selective queries (~10â€“20% of the dataset).
For boolean fields, indexing doesnâ€™t offer much benefit since there are only two possible values.
Would you like a MongoDB explain() query example to analyze index performance? ðŸš€


============================================================================================================================================================



compound index: 

-> A compound index in MongoDB is an index that includes multiple fields. It allows you to create an index on more than one field in a 
document, enabling efficient query performance for queries that involve those fields.
-> Compound indexes are larger than single-field indexes
-> The order of fields in a compound index is critical

syntax: 
db.collection.createIndex({ field1: 1, field2: -1 });
field1: 1 means the field is indexed in ascending order.
field2: -1 means the field is indexed in descending order.

EX: 
db.collection.createIndex({ name: 1, age: 1 });
Initial Data:
[
  { name: "Alice", age: 30 },
  { name: "Bob", age: 25 },
  { name: "Alice", age: 35 }
]
With a compound index { name: 1, age: 1 }, the data is ordered as:
[
  { name: "Alice", age: 30 }
  { name: "Alice", age: 35 }
  { name: "Bob", age: 25 }
]

How Does It Work?
A compound index sorts and organizes data by the specified fields in the order defined. 
It essentially acts as a "multi-level" sorting system:
First sorts by the first field (field1).
Then sorts by the second field (field2) for documents with the same field1 value.

Use Cases for Compound Indexes:

1. Multi-Field Queries
If your queries frequently filter or sort by multiple fields, a compound index can optimize performance.
Example: db.collection.createIndex({ age: 1, gender: 1 });
Query:db.collection.find({ age: { $gt: 30 }, gender: "male" });

2. Sorting
Compound indexes can be used to optimize sorting queries.
Example: db.collection.createIndex({ age: 1, salary: -1 });
Query: db.collection.find({}).sort({ age: 1, salary: -1 });
If you are not using indexes and you do a sort on large amount of documents, you can actually timeout because mongodb has a threshold of 
32 megabytes in memory for sorting and if you don't have index mongodb will essentially fetch all your docuemnts into memory and do the 
sort there 


3. Matching a Subset of Fields
A compound index can also be used to optimize queries involving only the first field or a prefix subset of fields.
Example: db.collection.createIndex({ age: 1, gender: 1 });
Optimized: db.collection.find({ age: { $gt: 30 } });
Not optimized: db.collection.find({ gender: "female" });
The query does not use the index fully because gender is not the first field in the compound index.


Queries That Benefit

1. Only contain age field
2. Both Fields in Query


Using Indexes for Sorting : 
==========================
available Indexes: 
  {
    v: 2,
    key: { 'dob.age': 1, gender: 1 },
    name: 'dob.age_1_gender_1'
  }

db.person.explain().find({"dob.age": 35}).sort({gender: 1})


If you are not using indexes and you do a sort on large amount of documents, you can actually timeout because mongodb has a threshold of 
32 megabytes in memory for sorting and if you don't have index mongodb will essentially fetch all your docuemnts into memory and do the 
sort there 

if you have millions of documents, you fetch so many documents that an in-memory sort is just not possible and
you need an index which is alredy sorted so that mongodb doesn't have to sort in memory but can just take the order you have in the index.


indexes are not only for searching but also for sorting.

because we have sorted list of elements of index.

mongoDB can utilized in case of you want to sort in the same way that index list is sorted.

Now this is another cool feature of indexes, since we  have an ordered list of values alredy, mongoDB can utilize that to quickly give
us back the order of documents we need.


So sometimes you also need an index not just to speed up the query but also to be able to sort at all.



============================================================================================================================================================



Default Index: 
==============
this is derfault Index: 
{ v: 2, key: { _id: 1 }, name: '_id_' },



============================================================================================================================================================


unique: true
============


When you create an index with "unique: true", MongoDB enforces uniqueness on that field across all documents in the collection. 
This means:
No two documents can have the same value for that indexed field.
If you try to insert or update a document with a duplicate value, MongoDB will throw an error.

ðŸ“Œ Example 1: Enforcing Unique User Emails
Letâ€™s say we have a users collection, and we want to ensure that email addresses are unique.

âœ… Creating a Unique Index on email Field
db.users.createIndex({ email: 1 }, { unique: true });
This ensures no two users can have the same email.


ðŸ“Œ Example 2: Unique Index on Multiple Fields (Compound Index)
We can create a unique compound index to ensure that a combination of two fields is unique.

âœ… Ensuring Each Seller Can Have Only One Product with the Same Name
db.products.createIndex({ seller: 1, productName: 1 }, { unique: true });
A seller cannot add two products with the same name.
But different sellers can add products with the same name.

âœ… Valid Inserts
db.products.insertMany([
  { seller: "Max", productName: "Laptop" },  // âœ… Allowed
  { seller: "John", productName: "Laptop" }  // âœ… Allowed (different seller)
]);

âŒ Invalid Insert (Duplicate Seller & Product Name)
db.products.insertOne({ seller: "Max", productName: "Laptop" });
ðŸ’¥ Error: "E11000 duplicate key error" â†’ Max already has a "Laptop".


ðŸ“Œ Things to Keep in Mind
1ï¸âƒ£ unique: true works only if there are no duplicate values already.
If duplicates exist, MongoDB wonâ€™t allow the index creation unless you remove duplicates first.
2ï¸âƒ£ null values are treated as the same value when using unique: true.
If a field is null, MongoDB allows only one document with null.
Example:
db.users.createIndex({ phoneNumber: 1 }, { unique: true });

{ name: "Alice", phoneNumber: null } âœ… Allowed
{ name: "Bob", phoneNumber: null } âŒ Error!



============================================================================================================================================================



Partial Filter: 
================

âž¡ï¸ In a partial filter, we define a condition, and the index is applied only to the documents that meet/pass this condition, instead of indexing the entire field.

-> It reducing the index size and improving query performance for specific queries.

for example i have 1 millions of documents and i want to do something for employees whose service_age is more than 50 years then 
is it more correct/optimised way to create index on only those documents where service_age > 50  rather than whole age fileld.

db.senwell.createIndex({ service_age: 1 }, { partialFilterExpression: { service_age: { $gte: 50 } } })

Query Not Using the Index: 
db.senwell.find({ service_age : { $lt: 50 }});
This query will not use the index because documents with service_age < 50 are not included in the index

Example 2: Index Only Non-Null Fields
[
  { _id: 1, status: "active", age: 25 },
  { _id: 2, status: "inactive", age: 30 },
  { _id: 3, status: "active", age: null },
  { _id: 4, status: "inactive", age: null }
]
Question: Create index on documents which contain age field.
Query : db.tb.createIndex({ age: 1 }, { partialFilterExpression: { age: { $exists: true } } });  // _id 3 and 4 not included
supported Query : db.tb.find({ age: { $gt: 20 } });

Question: create index on score field but include only documnets where status is active
db.tb.createIndex({ score: 1 }, { partialFilterExpression: { status: "active" } });
supported Query :db.tb.find({ score: { $gte: 85 }, status: "active" });
Not Supported :  db.tb.find({score: 20});  // here it perform COLLSCAN instaed of IXSCAN because you didn't mention status of document.
Note: while seaching for documents make sure you have added correct filelds so that index will applied correctly.

compound Index + Partial Filter:
db.tb1.createIndex({age: 1, gender: 1}, { partialFilterExpression: { age:{ $gte: 31 }, gender: { $exists: true } } } );



============================================================================================================================================================



TTL Index (Time to Live Index):
============================
A TTL (Time to Live) index is a special type of index that "automatically removes documents from a collection after a specified period". 
This is particularly useful for managing data that becomes irrelevant or obsolete after a certain time, such as:


âœ… Good For:
User sessions (e.g., auto-delete login sessions after 30 minutes).
Temporary data (like cache or logs)
Logs (e.g., store error logs for 7 days and delete old ones).
OTP verification codes (e.g., delete unused OTPs after 5 minutes).
Temporary notifications (e.g., clear expired alerts).
Expiring tokens.


Key Points to Remember:

1. Field Type: The TTL index must be on a field with a Date type.
2. Partial Expiration: TTL index does not expire a portion of a documentâ€”either the entire document is removed or it stays.
3. Background Process: Expiration is handled by a background thread, so it may not happen exactly at the second the document expires.
4. No Manual Control: You cannot use TTL to "manually" delete documents on demandâ€”it works based solely on the time value.
5. Compound Indexes: TTL indexes cannot be compound indexes; they must be single-field indexes.
TTL indexes delete entire documents, not just data from the index.

How TTL Index Works
You create a TTL index on a date field in a document.
MongoDB automatically deletes documents when the indexed field's value is older than the specified expiration time.
Deletion occurs in the background at regular intervals (every 60 seconds by default).

Example:

1. Scenario
You have a collection named "sessions" that stores user session data. 
You want sessions to expire 1 hour (3600 seconds) after their creation.

Query:  db.sessions.createIndex( { createdAt: 1 },  { expireAfterSeconds: 3600 } );  // 1 hour
> [
  {
    "v": 2,
    "key": { "createdAt": 1 },
    "name": "createdAt_1",
    "expireAfterSeconds": 3600
  }
]
createdAt: The field storing the document's creation date (must be a valid Date object).
expireAfterSeconds: Specifies the TTL duration (in seconds).
Query: db.sessions.insertOne({ sessionId: "abc123", userId: 1, createdAt: new Date() });
After 3600 seconds, MongoDB will automatically delete this document


Query: db.logs.createIndex({ timestamp: 1 }, { expireAfterSeconds: 604800 });  // Automatically delete logs after 7 days.
Query: db.cache.createIndex({ cachedAt: 1 }, { expireAfterSeconds: 86400 });  // Cache data for 24 hours.



ðŸ” TTL Index vs. Capped Collection â€“ When to Use?

Feature                  TTL Index                          Capped Collection
---------------------------------------------------------------------------------
Purpose                  Delete expired data               Store only recent data
How It Works?            Removes documents based on time  Keeps a fixed number of documents
Use Case                 Session data, OTPs, logs         Real-time logs, chat messages, sensor data
Data Deletion            Deletes documents permanently    Overwrites oldest data
Storage Control          No size control                  Fixed storage size




============================================================================================================================================================



Covered Query in MongoDB: 
=========================

-> A covered query is a query in MongoDB that is fully satisfied using an index without needing to examine the actual documents (totalDocsExamined) in the collection. 
This significantly improves query performance because it avoids disk I/O and document retrieval.
also since we don't have examine the documents (totalDocsExamined) the time is 0 milliseconds.

Conditions for a Covered Query: 
------------------------------
For a query to be considered covered:

1. All Fields in the Query Must Be Indexed.
2. The fields used in the "query filter" must be part of an index.
3. All Fields in the "Projection" Must Be Indexed:
4. No "fetch" or "scan" of the collection's documents is required:
MongoDB does not access the actual documents everything is resolved from the index.
b
Input Data: 
db.people.insertMany([
  { "_id": 1, "name": "Alice", "age": 30, "city": "New York" },
  { "_id": 2, "name": "Bob", "age": 25, "city": "Los Angeles" },
  { "_id": 3, "name": "Charlie", "age": 35, "city": "Chicago" }
])

Index Creation: 
db.people.createIndex({ name: 1, age: 1 });

Covered Query Example:
db.people.find({ name: "Alice" }, { name: 1, age: 1, _id: 0 });
Filter: { name: "Alice" } is covered by the index { name: 1, age: 1 }.
Projection: { name: 1, age: 1, _id: 0 } retrieves fields present in the index only.


You can use the explain() method to verify whether a query is covered. 
If the FETCH stage is absent in the winningPlan, the query is covered also if "totalDocsExamined" is 0 then also its covered query.
db.people.explain("executionStats").find({ name: "Alice" }, { name: 1, age: 1, _id: 0 });

Benefits of Covered Queries:
0. Covered queries are ideal for read-heavy applications where specific fields are queried often
1. Improved Performance
2. Avoids reading actual documents from the collection as the (totalDocsExamined) are 0.
3. Reduces Disk I/O
4. Works entirely from the index, which is faster
5. Efficient Use of Resources
6. Minimizes memory and CPU usage for query execution


Limitations: 

1. All Required Fields Must Be Indexed, If any queried or projected field is not in the index, the query won't be covered
2. If documents are frequently updated, maintaining indexes for covered queries can add overhead





How mongodb rejects a plan: 
==============================

db.users.insertMany([
  { name: "Adesh", age: 23, sex: "male" },
  { name: "Akshay", age: 25, sex: "male" },
  { name: "Rahul", age: 24, sex: "male" },
  { name: "Sneha", age: 23, sex: "female" },
  { name: "Riya", age: 26, sex: "female" },
  { name: "Mohit", age: 27, sex: "male" }
]);




============================================================================================================================================================








Multi Key Index

-> A multi key index is an index that created on an array field.
-> MongoDB will create separate index for each value of array element.
-> Since arrays can store multiple values, a multi-key index "indexes each element" in the array separately, making queries on array fields much faster
-> Space will be more compared to normal index.
-> Keep in mind that using multikey indexes comes with certain considerations, such as increased index size 
and potential performance impacts during updates to the array field.


When you create an index on an array field, MongoDB "creates a separate index entry for each value inside the array".
This allows MongoDB to efficiently search for documents where any of the array values match the query.

ðŸ”¹ Example: Let's say we have a products collection:

db.products.insertMany([
  { _id: 1, name: "Laptop", tags: ["electronics", "gadgets", "computers"] },
  { _id: 2, name: "Smartphone", tags: ["electronics", "mobile"] },
  { _id: 3, name: "Headphones", tags: ["electronics", "audio"] }
]);

The tags field contains an array of values.
If we create a multi-key index on tags:
db.products.createIndex({ tags: 1 });
MongoDB will index each value separately, meaning:

electronics â†’ points to Laptop, Smartphone, Headphones
gadgets â†’ points to Laptop
computers â†’ points to Laptop
mobile â†’ points to Smartphone
audio â†’ points to Headphones

Now, if we search for all products with "electronics" in tags:
db.products.find({ tags: "electronics" });
âœ… MongoDB will use the multi-key index and return all matching products without scanning the entire collection.



ðŸš«  Limitations of Multi-Key Indexes
No Compound Index on Multiple Multi-Key Fields

You cannot create a compound index where two or more fields are arrays.
Example: This is not allowed:
db.products.createIndex({ tags: 1, categories: 1 }); // âŒ ERROR if both are arrays
Instead, you can create separate indexes on tags and categories.

ðŸš« Index Size Can Grow Quickly
Since each array element is indexed separately, multi-key indexes can consume more storage than regular indexes.
Be cautious when indexing very large arrays.


When to Use Multi-Key Indexes?
âœ… When searching within arrays (e.g., tags, categories, skills).
âœ… When documents have fields that store multiple values.
âœ… When filtering based on multiple choices (e.g., movies with multiple genres).




=============================================================================================================







Text Index: 
============


-> Single Text Index per collection.
-> Tokenization and stemming
-> Relevance score

db.bio.insert([
    {_id: 1, name: 'Adesh', bio: 'I am youtuber'},
    {_id: 2, name: 'Akshay', bio: 'I am youtuber and actor'},
    {_id: 3, name: 'Manoj', bio: 'student'},
    {_id: 4, name: 'Ram', bio: 'swimmer'},
    {_id: 5, name: 'Swarali', bio: 'youtuber'}
])

db.users.createIndex({name: "text"})  -> name_text
db.users.createIndex({name: 'text', bio: 'text'})  -> name_text_bio_text

myDB> db.bio.createIndex({name: 'text', bio: 'text'})
name_text_bio_text
myDB> db.bio.getIndexes()
[
  { v: 2, key: { _id: 1 }, name: '_id_' },
  {
    v: 2,
    key: { _fts: 'text', _ftsx: 1 },
    name: 'name_text_bio_text',
    weights: { bio: 1, name: 1 },
    default_language: 'english',
    language_override: 'language',
    textIndexVersion: 3
  }
]

myDB> db.bio.find({$text: {$search: 'youtube'}})
[
  { _id: 5, name: 'Swarali', bio: 'youtuber' },
  { _id: 1, name: 'Adesh', bio: 'I am youtuber' },
  { _id: 2, name: 'Akshay', bio: 'I am youtuber and actor' }
]


myDB> db.bio.find({$text: {$search: 'youtube and actor'}})
[
  { _id: 2, name: 'Akshay', bio: 'I am youtuber and actor' },
  { _id: 5, name: 'Swarali', bio: 'youtuber' },
  { _id: 1, name: 'Adesh', bio: 'I am youtuber' }
]

// exclude actor
myDB> db.bio.find({$text: {$search: 'youtube -actor'}})
[
  { _id: 5, name: 'Swarali', bio: 'youtuber' },
  { _id: 1, name: 'Adesh', bio: 'I am youtuber' }
]

myDB> db.bio.find({$text: {$search: 'student Ram'}})
[
  { _id: 4, name: 'Ram', bio: 'swimmer' },
  { _id: 3, name: 'Manoj', bio: 'student' }
]


// check score of query
db.bio.find({$text: {$search: 'student Adesh'}}, {hamaraScore: {$meta: 'textScore'}})
[
  { _id: 1, name: 'Adesh', bio: 'I am youtuber', hamaraScore: 1.1 },
  { _id: 3, name: 'Manoj', bio: 'student', hamaraScore: 1.1 }
]