### What is Docker?
===================
-> Docker is a "platform" used to develop, ship, and run applications inside lightweight, portable "containers".
-> Docker is built on basic linux concepts.



### Why Use Docker?
===================
Docker helps developers package applications and their dependencies into containers, making them easy to run anywhere‚Äîon a developer‚Äôs laptop, a cloud server, 
or a production machine.

you can do both:
Run each application in a separate container ‚úÖ (Best practice - Isolated environments (no conflicts))
Run all applications inside the same container ‚ùå (Not recommended - Dependency conflicts -  If one app crashes, everything goes down)


Problems Docker Solves
üõë 1. "It works on my machine, but not on yours!"
‚úÖ Solution: Docker ensures the app runs the same way everywhere by packaging everything (code, libraries, dependencies) inside a container.

üõë 2. Dependency Conflicts
‚úÖ Solution: Each container has its own isolated environment, so different apps with different dependencies can run on the same system without conflicts.
Example:
One app needs Python 3.8, another needs Python 3.10 ‚Üí No problem! Each runs in its own container.

üõë 3. Difficult Deployment
‚úÖ Solution: With Docker, you package everything once and run it anywhere. No need to manually install dependencies on every server.
Example:
A developer can build a Docker image locally and deploy it to AWS, Azure, or Google Cloud without modifications.

üõë 5. Scaling Apps is Hard
‚úÖ Solution: Docker works with tools like Kubernetes to scale applications easily. You can quickly add or remove containers as traffic increases or decreases.

üõë 4. Wasting Resources with Virtual Machines (VMs)
‚úÖ Solution: Unlike VMs, "Docker shares the OS kernel", making it much lighter and faster.

|-------------------|--------------------------------------|----------------------------------|
| Feature           | Virtual Machine (VM)                 | Docker Container                 |
|-------------------|--------------------------------------|----------------------------------|
| Startup Time      | Minutes                              | Seconds                          |
| Size              | GBs (includes full OS)               | MBs (only app + dependencies)    |
| Performance       | Slower (needs full OS per VM)        | Faster (shares OS)               |
| Resource Usage    | Heavy (each VM needs CPU/RAM)        | Lightweight                      |
|-------------------|--------------------------------------|----------------------------------|

Would you like me to format it differently or add more details? üöÄ




When Should You Use Docker?
‚úî When you want consistent environments across development, testing, and production.
‚úî When deploying apps to cloud services like AWS, Azure, or Google Cloud.
‚úî When running microservices (breaking an app into smaller, independent services).
‚úî When you need fast, isolated environments without using heavy VMs.




Docker Architecture: 
====================

1. Docker Follows a Client-Server Architecture:
The Docker client communicates with the Docker daemon (server) using REST API, CLI, or SDKs.
The Docker Engine (daemon) runs in the background and handles building, running, and managing containers.

2. Containers Are Just Processes (But Isolated):
Containers are lightweight processes running on the host machine.
Unlike regular processes, each container has its own isolated filesystem, network, and dependencies.

3. Containers Share the Host OS Kernel:
All containers share the kernel of the host OS, not the full OS itself.
This is what makes Docker more lightweight than virtual machines.

4. Understanding the Kernel:
The kernel is the core of an OS, managing hardware resources like CPU, memory, and storage.
Different OS kernels provide different system APIs, which is why applications built for one OS cannot run on another without compatibility layers.

5. Why Can't We Run Windows Apps on Linux?
Applications interact with the OS kernel using system calls (APIs).
Since Windows and Linux have different kernels, applications are not natively compatible between them.

6. Running Containers on Different Operating Systems:
Linux Host ‚Üí Runs only Linux containers because they rely on the Linux kernel.
Windows Host ‚Üí Can run both Windows and Linux containers, but not at the same time.
Windows uses a lightweight VM (via WSL 2) to run Linux containers.
Docker Desktop automatically manages whether a container should run in WSL 2 or directly on Windows.
macOS Host ‚Üí Cannot run macOS containers (Apple does not support this).
Instead, Docker on macOS runs Linux containers inside a lightweight Linux VM (using HyperKit).


Windows can run both Windows and Linux containers using WSL 2 (Windows Subsystem for Linux 2) and Hyper-V:
Windows Containers: Run directly on the Windows kernel using the Windows Host OS.
Linux Containers: Run inside a lightweight Linux VM (provided by WSL 2 or Hyper-V) that contains a Linux kernel.

Docker Desktop automatically manages whether a container should run in WSL 2 or directly on Windows.




Virtual machine vs containers :
================================

### **Difference Between Virtual Machine (VM) and Docker Container**  

|----------------------|-------------------------------------------------|-----------------------------------------|
| Feature              | **Virtual Machine (VM)**                        | **Docker Container**                    |
|----------------------|-------------------------------------------------|-----------------------------------------|
| **Isolation**        | Fully isolated, runs its own OS                 | Isolated but shares the host OS kernel  |
| **OS Requirement**   | Each VM has a full OS (Linux, Windows, etc.)    | Uses the host OS kernel, no full OS     |
| **Kernel**           | Has its own kernel                              | Shares the host OS kernel               |
| **Startup Time**     | Slow (minutes)                                  | Fast (seconds)                          |
| **Size**             | Large (GBs, includes full OS)                   | Small (MBs, only app & dependencies)    |
| **Performance**      | Heavier, requires more CPU/RAM                  | Lightweight, uses fewer resources       |
| **Resource Usage**   | Requires dedicated CPU, RAM, and storage        | Shares system resources efficiently     |
| **Portability**      | Less portable (OS-dependent)                    | Highly portable (runs anywhere with Docker) |
| **Security**         | Stronger isolation (separate OS)                | Weaker isolation (shared kernel)        |
|----------------------|-------------------------------------------------|-----------------------------------------|

---

### **Can We Use Multiple VMs on the Same Machine?**  
‚úÖ **Yes, we can run multiple VMs on the same machine** using a **hypervisor** (like **VMware, VirtualBox, or Hyper-V**).  
- Each VM operates as a **completely independent machine**, running its own **OS, applications, and configurations**.  
- However, **running multiple VMs requires significant CPU, RAM, and storage**, since each VM includes a **full OS**.  

---

### **Docker vs. VMs: Which One to Use?**  
‚úî **Use VMs** when:  
   - You need **full OS isolation** (e.g., running Windows & Linux side by side).  
   - You require **high security** (stronger isolation between applications).  
   - Running legacy applications that need a **specific OS**.  

‚úî **Use Docker** when:  
   - You need **lightweight, fast, and portable** deployments.  
   - You want to **run multiple applications with minimal resource usage**.  
   - You need **scalability** (e.g., deploying microservices).  

Would you like a **diagram** to visualize how VMs and Docker work? üöÄ





Key Concepts of Docker:
=======================

1Ô∏è‚É£. Docker Containers:

-> Containers are lightweight, standalone, and portable.
-> They package everything needed to run an application, including code, dependencies, and configurations.
-> Containers are isolated from both the host system /Docker host and other containers. However, it does not run independently of the operating system‚Äîit shares the 
host OS kernel while maintaining its own user-space environment.
-> This prevents dependency conflicts between applications running on the same machine.
-> A container provides an isolated environment separate from your PC.
-> However, it does not run independently of the operating system‚Äîit shares the host OS kernel while maintaining its own user-space environment.
-> Docker container does not have its own OS. It only has its own isolated filesystem, network, and dependencies, but it still shares the host OS kernel.
-> Unlike virtual machines (VMs), containers do not include a full operating system. Each container shares the host OS kernel but runs in its own isolated user space.
-> This makes containers faster and more efficient than VMs.
-> Each container can have a different user-space environment (e.g., different dependencies, libraries, and tools).
However, all containers must be compatible with the host OS kernel.
-> A container is special kind of process  running on the host OS. Unlike regular processes, it has a dedicated filesystem, network, and isolated runtime 
environment provided by its Docker image thats why its special kind of process.

-> Docker host: A Docker host is the machine (computer or server) where Docker is installed and running. It is responsible for managing and running containers.
It could be:
‚úÖ Your PC or laptop (Windows, macOS, Linux), A Cloud server (AWS, Azure, Google Cloud), A Dedicated server running Linux or Windows
-> you cannot run Windows, Linux, and macOS containers all on the same Docker host at the same time. 
ex: 
1Ô∏è‚É£. Linux Containers on Linux: 
If your Docker host is Linux, you can run Linux containers natively.
Windows containers will not run on a Linux host natively.
When you run a Linux container on a Linux host, it directly uses the host's Linux kernel.

2Ô∏è‚É£. Windows Containers on Windows
If your Docker host is Windows, you can run Windows containers natively.
Linux containers can be run using WSL 2 (Windows Subsystem for Linux) or using Docker's LinuxKit VM.
If your "Docker host" is Windows, you cannot run Windows and Linux containers at the same time. But you can switch between them.
A Windows container must use a Windows host kernel (which is why you can't run a Windows container on a Linux host).

3Ô∏è‚É£. macOS Containers?
macOS does not support native macOS containers because Apple does not provide a macOS container runtime.
On a Mac, Docker actually runs a Linux virtual machine under the hood (via Docker Desktop) to run Linux containers.
Windows containers cannot run on macOS.
macOS cannot run macOS containers, so it uses a Linux VM to run Linux containers.


|-------------------|-----------------------------|--------------------------------|
| Feature           | Virtual Machine (VM)        | Docker Container               |
|-------------------|-----------------------------|--------------------------------|
| Own OS            | ‚úÖ Yes (Includes full OS)   | ‚ùå No (Shares host OS kernel) |
| Kernel            | Each VM has its own kernel  | Uses host OS kernel            |
| Size              | Large (GBs)                 | Small (MBs)                    |
| Startup Time      | Slow (minutes)              | Fast (seconds)                 |
|Performance        | Heavier (more resources)    | Lighter (faster)               |
|-------------------|-----------------------------|--------------------------------|
    




2Ô∏è‚É£. Docker Images

-> A Docker image is a lightweight, standalone, and "executable package" that includes
‚úÖ Application code (e.g., a Node.js app, Python script, etc.)
‚úÖ Dependencies (e.g., libraries, frameworks, runtimes)
‚úÖ Configuration files (e.g., environment variables, ports, settings)
‚úÖ File system snapshot (includes all necessary files)
üëâ Think of a Docker image as a "blueprint" or "template" for creating containers.
-> You can create Docker images from a Dockerfile (a configuration file that defines the image) or pull them from a public or private registry like Docker Hub.
You pull or build a Docker image ‚Üí "docker pull node:18-alpine"
-> we can package our application into a image and run it virtually everywhere. this is beauty of docker.
-> Every Docker image has its own base image, either an official one, a custom one, or scratch.

What is a Base Image?
A base image is the foundation of a Docker image. It provides an operating system or runtime environment on which your application runs.
How Docker Images Stack (Layers)
Each base image creates a new layer in the final image.
For example, this Dockerfile:

dockerfile
---
FROM node:18-alpine
WORKDIR /app
COPY . .
RUN npm install
EXPOSE 3000
CMD ["npm", "start"]
---
Creates the following layered structure:
1Ô∏è‚É£ node:18 (Base image with Node.js)
2Ô∏è‚É£ WORKDIR /app (Sets working directory)
3Ô∏è‚É£ COPY . . (Copies project files)
4Ô∏è‚É£ RUN npm install (Installs dependencies)
5Ô∏è‚É£ EXPOSE 3000 (Opens port)
6Ô∏è‚É£ CMD ["npm", "start"] (Defines the start command)

Each layer is cached by Docker, making builds faster.




Key Characteristics of a Docker Image:
1Ô∏è‚É£ Immutable ‚Äì Once built, an image cannot be changed. If modifications are needed, a new image must be created.
2Ô∏è‚É£ Layers & Caching ‚Äì
Docker images are built using multiple layers (each command in a Dockerfile creates a new layer).
This makes building and reusing images faster (since unchanged layers are cached).
3Ô∏è‚É£ Read-Only ‚Äì
The base image remains unchanged when a container runs.
When a container starts, Docker adds a writable layer on top of the image to store temporary changes.
4Ô∏è‚É£ Portable ‚Äì
A Docker image can be shared and deployed anywhere (local, cloud, or Kubernetes).
It is stored in a Docker registry (e.g., Docker Hub, AWS ECR, GitHub Container Registry).



How Does a Docker Image Work?
1Ô∏è‚É£ A Dockerfile defines how an image is built.
2Ô∏è‚É£ The image is built using docker build.
3Ô∏è‚É£ The image is stored in a registry (local or remote).
4Ô∏è‚É£ When you run docker run, a container is created from the image.

How They Work Together (Image - Container)
1Ô∏è‚É£ You pull or build a Docker image ‚Üí docker pull node:18-alpine
2Ô∏è‚É£ You create and run a container from the image ‚Üí docker run -d --name my-container node:18-alpine
3Ô∏è‚É£ The image stays the same, but containers can be stopped, started, or deleted without affecting the original image.

You can pull and run different versions of the same image in Docker. Each image version is identified by a tag.

‚úÖ Pull Different Versions of an Image
For example, to pull different versions of Ubuntu:

docker pull ubuntu:18.04   # Pull Ubuntu 18.04
docker pull ubuntu:20.04   # Pull Ubuntu 20.04
docker pull ubuntu:latest  # Pull the latest version (currently 22.04 or newer)


3Ô∏è‚É£. Dockerfile
-> A Dockerfile is a text document that contains "instructions on how to build a Docker image". It specifies the base image, installation steps, configuration, 
and any commands that should run when a container starts.

-> Since you modified the Dockerfile, you must rebuild the image before creating a new container
---
"docker build -t testapp:1.1 ." 
---
-t testapp:1.1 assigns a new tag to the updated image.
The . at the end specifies the current directory (where the Dockerfile is located).

Example: Simple Dockerfile for a Node.js App
dockerfile 1:
---
# Use an official Node.js image as the base
FROM node:18-alpine

# Set the working directory inside the container
WORKDIR /app

# Copy package.json and install dependencies
COPY package.json ./
RUN npm install

# Copy the rest of the app
COPY . .

# Expose the application port
EXPOSE 3000

# Run the app
CMD ["node", "server.js"]
---

Common instructions
Some of the most common instructions in a Dockerfile include:

FROM <image> - this specifies the base image that the build will extend.
WORKDIR <path> - this instruction specifies the "working directory" or the path in the image where files will be copied and commands will be executed.
COPY <host-path> <image-path> - this instruction tells the builder to copy files from the host and put them into the container image.
RUN <command> - this instruction tells the builder to run the specified command.
ENV <name> <value> - this instruction sets an environment variable that a running container will use.
EXPOSE <port-number> - this instruction sets configuration on the image that indicates a port the image would like to expose.
USER <user-or-uid> - this instruction sets the default user for all subsequent instructions.
CMD ["<command>", "<arg1>"] - this instruction sets the default command a container using this image will run.


This file creates an image that packages a Node.js app with all dependencies.
You can build and run this image as a container.



### Difference Between `Dockerfile` and Docker Image**  

|------------|-----------------------------------------------------------------------------|-----------------------------------------------------------------------------|
| Feature    | Dockerfile                                                                  | Docker Image (Final Product)                                                |
|------------|-----------------------------------------------------------------------------|-----------------------------------------------------------------------------|
| Definition | A text file that contains step-by-step instructions to build a Docker image.| A built, executable package created from a `Dockerfile`.                    |
| Purpose    | Defines how the image should be created                                     | The actual package that contains everything needed to run an application.   |
| State      | Editable (you can modify the file).                                         | Immutable (once built, it cannot be changed directly).                      |
| Usage      | Used as input for `docker build` to create an image.                        | Used as input for `docker run` to create a container.                       |
| Storage    | A simple text file stored in a project directory.                           | Stored locally or in a container registry (Docker Hub, AWS ECR, etc.).      |
|------------|-----------------------------------------------------------------------------|-----------------------------------------------------------------------------|

---

### **How They Work Together**
1Ô∏è‚É£ **You write a `Dockerfile`** ‚Üí It contains instructions like `FROM`, `COPY`, `RUN`, `CMD`.  
2Ô∏è‚É£ **You run `docker build`** ‚Üí This builds a **Docker Image** based on the `Dockerfile`.  
3Ô∏è‚É£ **You run `docker run`** ‚Üí This starts a **Docker Container** from the built image.  

---

### **Example of a Dockerfile**
```
# Use an official Node.js base image
FROM node:18-alpine  

# Set working directory inside container
WORKDIR /app  

# Copy application files
COPY . .  

# Install dependencies
RUN npm install  

# Expose port 3000
EXPOSE 3000  

# Run the application
CMD ["node", "server.js"]  
```

- This `Dockerfile` defines how to build a Node.js app inside a container.  
- Running `docker build -t my-node-app .` creates a **Docker Image**.  




4Ô∏è‚É£. Docker Engine : 

Docker Engine is the core component of Docker that allows you to build, run, and manage containers, images. 
It runs as a background service (daemon) on your system and provides a way to communicate with containers using a CLI (Command-Line Interface) or REST API.

Key Components of Docker Engine
1Ô∏è‚É£ Docker Daemon (dockerd)
Runs in the background and manages images, containers, networks, and storage.
Listens for Docker API requests from the Docker CLI or other tools.

2Ô∏è‚É£ Docker CLI (docker)
A command-line tool that allows users to interact with the Docker Daemon.
Example commands:
---
docker run nginx
docker ps
docker stop container_id
---

3Ô∏è‚É£ REST API
Provides a way for applications and automation tools to communicate with Docker Daemon.

Docker Engine Manages the Following:
‚úÖ Containers ‚Äì Creating, running, stopping, and deleting containers.
‚úÖ Images ‚Äì Pulling, building, storing, and removing images.
‚úÖ Networks ‚Äì Managing container communication.
‚úÖ Storage ‚Äì Handling volumes and persistent data.


Docker Engine Workflow
üîπ Step 1: The user runs a command using the Docker CLI (docker run nginx).
üîπ Step 2: The CLI sends a request to the Docker Daemon.
üîπ Step 3: The Daemon pulls the required Docker Image from Docker Hub (if not already available).
üîπ Step 4: The Daemon creates and runs a container based on the image.
üîπ Step 5: The user can manage the container (docker stop, docker restart, docker logs).


Types of Docker Engines
1Ô∏è‚É£ Docker Engine - Community (CE) ‚Üí Free and open-source for developers and small teams.
2Ô∏è‚É£ Docker Engine - Enterprise (EE) ‚Üí Paid version with extra security and support features for large businesses.




5Ô∏è‚É£. Docker Hub:
-> Its a "cloud-based registry" that allows you to "store" and "share" "Docker images".
-> You can "pull images" from the Docker Hub or "push" your own images to it.
How Docker Hub Works:
1Ô∏è‚É£ Pull an Image from Docker Hub
---
docker pull nginx
---
üîπ This downloads the nginx image from Docker Hub to your local system.
2Ô∏è‚É£ Run a Container from a Docker Hub Image
---
docker run -d -p 8080:80 nginx
---
üîπ Runs an nginx web server using the pulled image.
3Ô∏è‚É£ Push Your Own Image to Docker Hub

üîπ Step 1: Log in to Docker Hub
---
docker login
---

üîπ Step 2: Tag your image
---
docker tag my-app my-dockerhub-username/my-app:v1
---

üîπ Step 3: Push the image to Docker Hub
---
docker push my-dockerhub-username/my-app:v1
---

4Ô∏è‚É£ List All Images in Your Docker Hub Account
Visit: hub.docker.com
Log in and view your repositories.



6Ô∏è‚É£. Docker Compose:
üöÄ Docker Compose is a tool that allows you to define and manage multi-container Docker applications using a simple YAML file (docker-compose.yml). 
Instead of running multiple docker run commands manually,  .

Why Use Docker Compose?
‚úÖ Multiple Containers, One Command ‚Äì Easily manage multi-container applications (e.g., frontend + backend + database).
‚úÖ Simplifies Configuration ‚Äì Define everything in a single docker-compose.yml file.
‚úÖ Networking Made Easy ‚Äì Automatically creates a private network for containers to communicate.
‚úÖ Volume Management ‚Äì Handles persistent storage for databases and other services.
‚úÖ Scalable ‚Äì Easily scale containers up or down.
‚úÖ Environment Variables ‚Äì Store sensitive data like passwords separately using .env files.

What is a Multi-Container Docker Application?
üöÄ A multi-container Docker application is an application that runs multiple interconnected containers, each handling a specific part of the system. 
Instead of running everything in one container, you split your application into separate services, making it more scalable, modular, and maintainable.

Why Use Multi-Container Architecture?
‚úÖ Separation of Concerns ‚Äì Each container runs a specific service (backend, database, frontend, cache).
‚úÖ Scalability ‚Äì You can scale individual services independently (e.g., scale database separately from the backend).
‚úÖ Easy Maintenance & Updates ‚Äì Update or restart one service without affecting others.
‚úÖ Better Resource Management ‚Äì Services consume only the necessary resources instead of bloating a single container.
‚úÖ Microservices-Friendly ‚Äì Works well with microservices architectures.

Example: A Web Application with Multiple Containers
üõ† Imagine a full-stack web application with the following components:
Frontend ‚Äì React application running in one container
Backend ‚Äì Node.js API running in another container
Database ‚Äì PostgreSQL running in a separate container
Cache ‚Äì Redis running in another container

Multi-Container Setup Using "docker-compose.yml": 
---
version: '3.8'

services:
  frontend:
    image: node:18
    container_name: react-app
    working_dir: /app
    volumes:
      - .:/app
    ports:
      - "3000:3000"
    command: npm start
    depends_on:
      - backend

  backend:
    image: node:18
    container_name: node-api
    working_dir: /api
    volumes:
      - .:/api
    ports:
      - "5000:5000"
    command: npm start
    depends_on:
      - database
      - cache

  database:
    image: postgres:latest
    container_name: postgres-db
    restart: always
    environment:
      POSTGRES_USER: user
      POSTGRES_PASSWORD: password
      POSTGRES_DB: mydb
    ports:
      - "5432:5432"

  cache:
    image: redis:latest
    container_name: redis-cache
    restart: always
    ports:
      - "6379:6379"
---

Running the Multi-Container Application
1Ô∏è‚É£ Start all containers
---
docker-compose up -d
---
üîπ This will start frontend, backend, database, and cache services in separate containers

2Ô∏è‚É£ Check running containers
---
docker-compose ps
---

3Ô∏è‚É£ Stop all containers
---
docker-compose down
---


Here‚Äôs your table in a proper format:  

|-----------------|-----------------------------------------|-------------------------------------------|
| Feature         | Single Container (Monolithic)           | Multi-Container (Microservices)           |
|-----------------|-----------------------------------------|-------------------------------------------|
| Scalability     | Hard to scale individual parts          | Easily scale each service separately      |
| Performance     | High resource usage                     | Optimized usage per service               |  
| Fault Isolation | If one part crashes, everything crashes | Other services continue running           |
| Maintainability | Difficult to update components          | Easier to update/fix individual parts     |
| Reusability     | Cannot reuse components easily          | Services can be reused elsewhere          |
|-----------------|-----------------------------------------|-------------------------------------------|





A Dockerfile and a Docker Compose (YAML) file serve different purposes in Docker:

-> A Dockerfile is a script containing instructions to build a Docker image.
-> A Docker Compose YAML file is used to define and run multiple containers as a service.

### 1. Dockerfile
- A Dockerfile is a script containing instructions to build a Docker image.
- It defines the environment, dependencies, and commands to run inside a container.
- Used with `docker build` to create an image.

Example of a Dockerfile:
```dockerfile
# Base image
FROM node:18

# Set working directory
WORKDIR /app

# Copy package.json and install dependencies
COPY package.json .
RUN npm install

# Copy source code
COPY . .

# Expose port and start application
EXPOSE 3000
CMD ["npm", "start"]
```

### 2. Docker Compose File (docker-compose.yml)
- A Docker Compose YAML file is used to define and run multiple containers as a service.
- Instead of managing individual containers manually, you can define services, networks, and volumes in one place.
- Used with `docker-compose up` to start multiple services.

**Example of a `docker-compose.yml` file:**
```yaml
version: '3'
services:
  app:
    build: .
    ports:
      - "3000:3000"
    volumes:
      - .:/app
    depends_on:
      - db

  db:
    image: postgres:15
    environment:
      POSTGRES_USER: user
      POSTGRES_PASSWORD: password
      POSTGRES_DB: mydb
    ports:
      - "5432:5432"
```

### Key Differences:
| ---------------- | --------------------------------------------- | ----------------------------------------------------- |
| Feature          | Dockerfile                                    | Docker Compose (YAML)                                 |
| ---------------- | --------------------------------------------- | ----------------------------------------------------- |
| **Purpose**      | Builds a single **Docker image**              | Manages **multiple containers/services**              |
| **Scope**        | Defines how a container is **built**          | Defines how containers **run and interact**           |
| **Command**      | Used with `docker build`                      | Used with `docker-compose up`                         |
| **Usage**        | Creates an image for a single service         | Defines multi-container applications (e.g., app + DB) |
| **Dependencies** | Only the image setup, no service dependencies | Allows linking containers using `depends_on`          |
| ---------------- | --------------------------------------------- | ----------------------------------------------------- |

### **How They Work Together**
- A **Dockerfile** is used to build an image.
- A **docker-compose.yml** file can reference this image and configure multiple services.

Would you like an example where both are used together? üöÄ







7. Docker Volumes üóÑÔ∏è

A Docker Volume is a persistent storage (any data storage device that retains data after power to that device is shut off) mechanism used to store data outside of a 
container‚Äôs lifecycle. This means data is not lost when a container is stopped, removed, or recreated.


Why Use Docker Volumes?
‚úÖ Persistent Storage ‚Äì Keeps data even if the container is deleted.
‚úÖ Container Independence ‚Äì Data can be shared across multiple containers.
‚úÖ Performance Optimization ‚Äì Faster than bind mounts when dealing with large amounts of data.
‚úÖ Backup & Restore ‚Äì Easily backup or migrate data between containers


### Types of Docker Volumes  

|-------------------|-------------------------------------------------------------------------------|---------------------------------------------------------------|
| Volume Type       | Description                                                                   | Use Case                                                      |
|-------------------|-------------------------------------------------------------------------------|---------------------------------------------------------------|
| Anonymous Volume  | Temporary storage tied to a container, removed when the container is deleted. | Temporary logs, session data.                                 |
| Named Volume      | Persistent storage that can be shared across multiple containers.             | Databases, application data.                                  |
| Bind Mount        | Mounts a specific directory from the host machine into the container.         | Sharing host files with containers (e.g., local development). |
|-------------------|-------------------------------------------------------------------------------|---------------------------------------------------------------|

---

### **Working with Volumes**  

#### 1Ô∏è‚É£ Create & Use a Volume in a Container
```sh
docker volume create my_volume
docker run -d --name my_container -v my_volume:/app/data my_image
```
üìå This stores `/app/data` inside `my_volume`, keeping it safe even if `my_container` is deleted.  

#### 2Ô∏è‚É£ List All Volumes
```sh
docker volume ls
```

#### 3Ô∏è‚É£ Inspect a Volume
```sh
docker volume inspect my_volume
```

#### 4Ô∏è‚É£ Remove a Volume
```sh
docker volume rm my_volume
```

#### 5Ô∏è‚É£ Use a Volume in `docker-compose.yml`
```yaml
version: '3.8'

services:
  app:
    image: my_app
    volumes:
      - my_data:/app/data

volumes:
  my_data:
```
üìå **This ensures `my_data` persists across container restarts.**  

---

### **When to Use Docker Volumes?**  
‚úî **Databases** ‚Äì Store database files separately from containers.  
‚úî **Shared Data** ‚Äì Allow multiple containers to access the same data.  
‚úî **Persistent Logs** ‚Äì Store logs outside the container for debugging.  





8Ô∏è‚É£. Port Binding in Docker: 

-> Port binding is the process of mapping a port inside the container to a port on the host machine, allowing external access to services running inside the container.
-> you cannot add port mapping (-p) to an existing container when using docker start.
Port mappings (-p) are set at container creation (docker run).
Once a container is created, you cannot change its port mappings.
docker start can only restart an existing container with the same settings it was created with.

‚úÖ How Port Binding Works
When you run a Docker container, it has its own network environment. Services inside the container (like a web server or database) listen on ports inside the container, 
but they are not accessible from the host system unless you explicitly bind them

Syntax for Port Binding:
---
docker run -p <host_port>:<container_port> <image>
---
host_port ‚Üí The port on your local machine (host).
container_port ‚Üí The port inside the container.


For example:
---
docker run -d -p 8080:80 nginx
---
This maps port 80 inside the container to port 8080 on the host.
Now, you can access the Nginx web server at http://localhost:8080.


üéØ Examples of Port Binding
1Ô∏è‚É£ Running MySQL on a Specific Port
---
docker run -d -p 3307:3306 --name my_mysql mysql:8.0
---
3306 ‚Üí MySQL default port inside the container.
3307 ‚Üí Exposes it on port 3307 on the host.

Now, you can connect using: mysql -h 127.0.0.1 -P 3307 -u root -p


2Ô∏è‚É£ Running Multiple Containers on Different Ports
You can run multiple containers of the same image by binding them to different ports:
---
docker run -d -p 8081:80 nginx
docker run -d -p 8082:80 nginx
---
The first Nginx container is accessible at http://localhost:8081
The second Nginx container is accessible at http://localhost:8082

‚úÖ Checking Port Bindings
To see all running containers and their port mappings:
---
docker ps
---
Example output:
CONTAINER ID   IMAGE   PORTS                     NAMES
a1b2c3d4e5f6   nginx   0.0.0.0:8080->80/tcp      my_nginx
This shows port 8080 on the host is mapped to port 80 inside the container.






9Ô∏è‚É£. Docker Network:üåê 


-> Docker networking allows containers to communicate with each other and with the outside world. 
-> It works like a private network inside your computer, where containers can talk to each other securely.

Think of it like Wi-Fi in your home:

Your laptop, phone, and smart TV are like containers.
Your Wi-Fi router is like Docker‚Äôs network system, connecting all devices.


üõ†Ô∏è Types of Docker Networks

Docker provides different network types, each suited for different use cases. You can check available networks using:
---
docker network ls
---


| ---------------- | -------------------------------------------------------------------------------------------- | ----------------------------------------------------------------------- |
| Network Type     | Description                                                                                  | Use Case                                                                |
| ---------------- | -------------------------------------------------------------------------------------------- | ----------------------------------------------------------------------- |
| Bridge (Default) | Containers can talk to each other inside the same network                                    |                                                                         |
| Host             | Containers share the host machine's network, removing isolation.                             | When you need the container to behave like a native app on your system. |
| None             | The container has no network access.                                                         | Running isolated workloads without external communication.              |
| Overlay          | Used in Docker Swarm to connect containers across multiple machines.                         | Scaling applications across multiple servers.                           |
| Macvlan          | Assigns real IP addresses to containers, making them act like physical devices on a network. | Running services that need their own unique IPs.                        |
| ---------------- | -------------------------------------------------------------------------------------------- | ----------------------------------------------------------------------- |

---

1Ô∏è‚É£ Default Bridge Network (Most Common)
By default, when you run a container, Docker assigns it to the bridge network. Containers in the same bridge network can talk to each other using their names.

---
docker network create my_custom_network
docker run -d --name db --network my_custom_network mysql
docker run -d --name app --network my_custom_network myapp
---

Now, the app container can connect to db using:

---
mysql -h db -u root -p
---


### **üõ†Ô∏è Useful Docker Network Commands**
#### **Check all networks**
```sh
docker network ls
```

#### **Inspect a network**
```sh
docker network inspect bridge
```

#### **Create a custom network**
```sh
docker network create my_network
```

#### **Run a container in a specific network**
```sh
docker run -d --network my_network --name my_container nginx
```

#### **Connect a running container to a network**
```sh
docker network connect my_network my_container






Dockerizing an Application üöÄ
------------------------------

Dockerizing an application means packaging the application and its dependencies into a Docker container so that it can run consistently across different environments.









### üöÄ **Most Common & Frequently Used Docker Commands**  


üöÄ Use `-d` when you want the container to keep running in the background!

The `-d` flag in Docker stands for "detached mode". It allows you to run a container in the background instead of keeping it attached to your terminal.  
The -d flag is used with "docker run" to start a new container in detached mode, but it is not used with "docker start", which is only for restarting an existing 
stopped container.

### Example Usage
```
docker run -d --name my_container ubuntu
```
üîπ This runs an Ubuntu container in the background.  

### Why Use `-d`?
‚úî Keeps the terminal free ‚Äì You can continue using the terminal while the container runs.  
‚úî Ideal for background services ‚Äì Useful for running databases, web servers, or APIs.  
‚úî Still manageable ‚Äì You can check logs (`docker logs my_container`) or attach back (`docker attach my_container`).  






---

### **üîπ Basic Docker Commands**
|---------------------|-----------------------------------------------|
| Command             | Description                                   |
|---------------------|-----------------------------------------------|
| `docker version`    | Check installed Docker version.               |
| `docker info`       | Display system-wide information about Docker. |
|---------------------|-----------------------------------------------|

---

### **üì¶ Image Management Commands**
|---------------------------------|---------------------------------------------------------------|
| Command                         | Description                                                   |
|---------------------------------|---------------------------------------------------------------|
| `docker pull <image>`           | Download an image from Docker Hub.                            |
| `docker images`                 | List all downloaded Docker images.                            |
| `docker rmi <image>`            | Remove a Docker image.                                        |
| `docker build -t my-image .`    | Build an image from a `Dockerfile` in the current directory.  |
|---------------------------------|---------------------------------------------------------------|

---

### **üö¢ Container Management Commands**

|-------------------------------------------------------|-----------------------------------------------------------------------------------------------|
| **Command**                                           | **Description**                                                                               |
|-------------------------------------------------------|-----------------------------------------------------------------------------------------------|
| `docker run -d -p 8080:80 --name my-container nginx`  | Run a container in the background and map ports.                                              |
| `docker ps`                                           | List all running containers.                                                                  |
| `docker ps -a`                                        | List all containers (including stopped ones).                                                 |
| `docker stop <container>`                             | Stop a running container.                                                                     |
| `docker start -ai <container_id>`                     | Start a stopped container in interactive mode                                                 |
| `docker start <container>`                            | Start a stopped container.                                                                    |
| `docker restart <container>`                          | Restart a container.                                                                          |
| `docker rm <container>`                               | Remove a container.                                                                           |
| `docker logs <container>`                             | View logs of a container.                                                                     |
| `docker exec -it <container> sh`                      | Access the container's shell while it is running.                                             |
| `docker exec -it <container> bash`                    | Access the container's shell (for Debian/Ubuntu-based images).                                |
|-------------------------------------------------------|-----------------------------------------------------------------------------------------------|

---

### **üõ†Ô∏è Volume Management Commands**
|-----------------------------------|-------------------------|
| Command                           | Description             |
|-----------------------------------|-------------------------|
| `docker volume create my-volume`  | Create a Docker volume. |
| `docker volume ls`                | List all volumes.       |
| `docker volume inspect my-volume` | Inspect volume details. |
| `docker volume rm my-volume`      | Remove a volume.        |
|-----------------------------------|-------------------------|

---

### **üìÇ Network Management Commands**
|--------------------------------------------------|------------------------------------|
| Command                                          |  Description                       |
|--------------------------------------------------|------------------------------------|
| `docker network ls`                              | List all networks.                 |
| `docker network create my-network`               | Create a custom network.           |
| `docker network connect my-network my-container` | Connect a container to a network.  |
| `docker network inspect my-network`              | Inspect network details.           |
| `docker network rm my-network`                   | Remove a network.                  |
|--------------------------------------------------|------------------------------------|

---

### **üìù Docker Compose Commands**
|-----------------------------------------|------------------------------------------------------|
| Command                                 | Description                                          |
|-----------------------------------------|------------------------------------------------------|
| `docker-compose up`                     | Start all services defined in `docker-compose.yml`.  |
| `docker-compose -f filename.yaml up -d` | Start all services defined in `docker-compose.yml`.  |
| `docker-compose down`                   | Stop and remove all services.                        |
| `docker-compose -f filename.yaml down`  | Start all services defined in `docker-compose.yml`.  |
| `docker-compose ps`                     | List all running services.                           |
| `docker-compose logs`                   | View logs of all services.                           |    
|-----------------------------------------|------------------------------------------------------|

---

### **üî• Clean Up Commands**
|---------------------------------|---------------------------------------------------------------|
| Command                         | Description                                                   |
|---------------------------------|---------------------------------------------------------------|
| `docker system prune`           | Remove unused images, containers, networks, and build cache.  |
| `docker image prune`            | Remove unused images.                                         |
| `docker container prune`        | Remove all stopped containers.                                |
| `docker volume prune`           | Remove all unused volumes.                                    |   
|---------------------------------|---------------------------------------------------------------|

---



Development workFlow: 
======================
we take application, it does not matter what kind of application it is or how its build. 
we take application and "dockerize" it. which means we make small change so that it can be run by docker.
how, we just add "dockerfile" to it. "dockerfile" is a "plain text file" which includes instructions that docker uses to package our application into image.
also A Dockerfile is a text document that contains "instructions on how to build a Docker image". It specifies the base image, installation steps, configuration, 
and any commands that should run when a container starts.
This Image contain everything our application need to run. for ex. A cut down OS. A runtime environment (eg Node/python), Applications files, Third party libraries,
environment variables and so on. so we create a docker file and give it to docker for packaging our application into a image.

once we have image we tell the docker to start a container using that image.
container is a process but special kind of process because it has its own file system which is provided by image.
so our application is loaded inside a container and this is how we run our application locally on development machine.
so instead of directly launching the application and running inside typical process we tell the docker to run it inside a container and in isolated environment.

Once we have this "image" we can push it to docker registry like docker hub, docker to docker hub is similar to git to github, its a storage for docker images that 
anyone can use. so once our "application image" is on docker hub then can pull it from any machine running docker. with this we can start the container in same way 
we do in development machine. we just tell docker to start a container using this image. 






Docker In Action: 
=================


Question>
i have simple node application inside my machine or you can say host machine and i have created a image from dockerfile and run the container from that image, 
now i have to fix some minor bug so should i create image once again or is there any command to simplyfy the process?

Answer>
Since you have already created a Docker image and are running a container, here are your options for making changes without rebuilding everything from scratch:
```
https://stackoverflow.com/questions/62193878/docker-container-not-updating-on-code-change
```

üîπ Option 1: Modify Files Inside the Running Container (Temporary Fix)

If the change is small and you want to test it quickly, you can:
-> However, changes made this way will be lost when you restart the container.

split terminal into two terminals, in one terminal enter this command to see logs of container: 
```
docker start -ai <container_id>
```

Enter this in 2nd terminal to make changes and see if anything broke from 1st terminal:
```
docker exec -it <container_id> sh
```

Edit the file using nano in 2nd terminal:
/app # nano server.js  // make changes in file and ctrl + O to save and ctrl + x to exit.
again check anything broke from 1st terminal.




üîπ Option 2: Mount Your Local Code Directory (Recommended for Development)
If you‚Äôre actively developing, you can avoid rebuilding the image repeatedly by using volume mounts.
```
docker run -d -p 5000:8080 -v ${PWD}:/vidly --name vidly aa712f2ca09f    // img name: movie-rental-app(aa712f2ca09f)
```
This mounts your local folder ($(pwd)) to /app inside the container.
Any changes in your local files will be reflected inside the container without rebuilding the image.
we are using "bind mount" volume.
What Happens to Data in a Bind Mount?

Since you're using a bind mount (-v "E:\z Placement\Mosh\React 18\Project\nodejs-docker:/app"), the data in your local machine's folder remains even if the container 
is stopped, restarted, or deleted.

‚úîÔ∏è If you restart the container (docker stop ‚Üí docker start)
‚Üí Your data inside "E:\z Placement\Mosh\React 18\Project\nodejs-docker" stays intact and will be available inside /app in the container.

‚úîÔ∏è If you remove the container (docker rm vidly)
‚Üí The container is gone, but your local files in "E:\z Placement\Mosh\React 18\Project\nodejs-docker" are still there.

‚úîÔ∏è If you delete the image (docker rmi mynodeimage)
‚Üí The image is gone, but your local files are unaffected.




üîπ Option 3: Rebuild the Image (When Changes Are Permanent)
If you made changes to your Node.js files and want a fresh image, do:

sh
Copy
Edit
docker build -t mynodeimage .
docker stop <container_id>
docker rm <container_id>
docker run -p 8080:8080 --name mynodeapp mynodeimage
(Replace mynodeimage and mynodeapp with your actual image and container names)